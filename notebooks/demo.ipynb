{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Healing Time Parser Demo\n",
    "\n",
    "This notebook demonstrates the self-healing time parser system that uses an LLM-based coding agent to automatically update parsing logic when encountering new time expression patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025\n",
      "Current working directory: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/notebooks\n",
      "Python executable: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/.venv/bin/python3\n",
      "Python path includes project root: True\n",
      "✓ coding_agent module found at: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/coding_agent/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Path setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root: the directory that contains notebooks/ as a subdirectory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Start from current directory and walk up until we find a directory with notebooks/ subdirectory\n",
    "project_root = None\n",
    "current = cwd\n",
    "while current != current.parent:  # Stop at filesystem root\n",
    "    if (current / \"notebooks\").exists() and (current / \"notebooks\").is_dir():\n",
    "        project_root = current\n",
    "        break\n",
    "    current = current.parent\n",
    "\n",
    "# If not found, fallback to current directory\n",
    "if project_root is None:\n",
    "    project_root = cwd\n",
    "    print(f\"⚠ Warning: Could not find project root (directory with notebooks/ subdirectory)\")\n",
    "    print(f\"   Using current directory as fallback: {project_root}\")\n",
    "\n",
    "# Add project root to path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python path includes project root: {str(project_root) in sys.path}\")\n",
    "\n",
    "# Verify coding_agent can be found\n",
    "try:\n",
    "    import coding_agent\n",
    "    print(f\"✓ coding_agent module found at: {coding_agent.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ coding_agent module not found: {e}\")\n",
    "    print(f\"  Please ensure you're using the correct Python environment where the package is installed.\")\n",
    "    print(f\"  Try: uv run jupyter notebook notebooks/demo.ipynb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n",
      "✓ Pandas display options configured for full column width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/coding_agent/llms.py:13: UserWarning: Field name \"validate\" in \"NodeLLMs\" shadows an attribute in parent \"BaseModel\"\n",
      "  class NodeLLMs(BaseModel):\n",
      "/Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/coding_agent/prompts.py:19: UserWarning: Field name \"validate\" in \"NodePrompts\" shadows an attribute in parent \"BaseModel\"\n",
      "  class NodePrompts(BaseModel):\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from coding_agent.agent import CodingAgentWorkflow\n",
    "from coding_agent.base import (\n",
    "    AnnotationState,\n",
    "    DEFAULT_RATE_LIMITING_CONFIG,\n",
    ")\n",
    "from coding_agent.error_queue import get_error_count, read_error_queue\n",
    "from coding_agent.llms import NodeLLMs\n",
    "from coding_agent.prompts import build_node_prompts\n",
    "from coding_agent.reloader import reload_parser\n",
    "from coding_agent.test_runner import run_pytest\n",
    "from time_parser import TimeParser\n",
    "from time_parser.wrapper import intercept_parser_errors\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "\n",
    "# Configure pandas display options\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Show full width of each column\n",
    "pd.set_option('display.width', None)  # Auto-detect terminal width\n",
    "pd.set_option('display.max_rows', 100)  # Show up to 100 rows (adjust as needed)\n",
    "\n",
    "print(\"✓ Pandas display options configured for full column width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logging configured\n"
     ]
    }
   ],
   "source": [
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"✓ Logging configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using gemini-3\n",
      "✓ LLM initialized: gemini-3\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemini LLM\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable not set\")\n",
    "\n",
    "# Try gemini-3\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-3-pro-preview\",\n",
    "        google_api_key=api_key,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=8192,\n",
    "    )\n",
    "    print(\"✓ Using gemini-3\")\n",
    "    print(f\"✓ LLM initialized: gemini-3\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to initialize gemini-3: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Demonstration\n",
    "\n",
    "Let's first examine the problem we're trying to solve - some timing descriptions fail to parse while others succeed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 129\n",
      "Columns: ['customer_id', 'deadline_at', 'timing_description', 'auxiliary_pretty']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>deadline_at</th>\n",
       "      <th>timing_description</th>\n",
       "      <th>auxiliary_pretty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>After the initial service appointment is completed.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: After the initial service appointment is completed.\",\\n        \"original_timing\": \"After the initial service appointment is completed.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"After the initial service appointment is completed.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>As soon as customer obtains pictures, potentially tomorrow as suggested by customer.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>In 3-5 business days, to allow time for the customer's internal discussion.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>March (or when weather warms up)</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: March (or when weather warms up)\",\\n        \"original_timing\": \"March (or when weather warms up)\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"March (or when weather warms up)\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>On December 18th, prior to the 4-5 PM appointment window.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id deadline_at  \\\n",
       "0            3         NaT   \n",
       "1            3         NaT   \n",
       "2            3         NaT   \n",
       "3            3         NaT   \n",
       "4            3         NaT   \n",
       "\n",
       "                                                                     timing_description  \\\n",
       "0                                   After the initial service appointment is completed.   \n",
       "1  As soon as customer obtains pictures, potentially tomorrow as suggested by customer.   \n",
       "2           In 3-5 business days, to allow time for the customer's internal discussion.   \n",
       "3                                                      March (or when weather warms up)   \n",
       "4                             On December 18th, prior to the 4-5 PM appointment window.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         auxiliary_pretty  \n",
       "0                                                                                                     {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: After the initial service appointment is completed.\",\\n        \"original_timing\": \"After the initial service appointment is completed.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"After the initial service appointment is completed.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "1  {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "2                             {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "3                                                                                                                                                              {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: March (or when weather warms up)\",\\n        \"original_timing\": \"March (or when weather warms up)\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"March (or when weather warms up)\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "4                                                                                   {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fixture file (use project_root from cell 1)\n",
    "fixture_path = project_root / \"tests\" / \"fixtures\" / \"follow_up_tasks_202512121435.jsonl\"\n",
    "if not fixture_path.exists():\n",
    "    raise FileNotFoundError(f\"Fixture file not found: {fixture_path}\")\n",
    "df = pd.read_json(str(fixture_path), lines=True)\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with parsing failures: 71\n",
      "\n",
      "Sample parsing failures:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>timing_description</th>\n",
       "      <th>deadline_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>After the initial service appointment is completed.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>As soon as customer obtains pictures, potentially tomorrow as suggested by customer.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>In 3-5 business days, to allow time for the customer's internal discussion.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>March (or when weather warms up)</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>On December 18th, prior to the 4-5 PM appointment window.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>By 9 AM on Monday (as promised by the agent).</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>At customer's earliest convenience</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>By 9 AM on Monday (as committed by the agent).</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>On December 19th, prior to the technician's arrival, which is after 2:30 PM.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Monday morning by 9 AM</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  \\\n",
       "0            3   \n",
       "1            3   \n",
       "2            3   \n",
       "3            3   \n",
       "4            3   \n",
       "5            3   \n",
       "6            3   \n",
       "7            3   \n",
       "8            3   \n",
       "9            3   \n",
       "\n",
       "                                                                     timing_description  \\\n",
       "0                                   After the initial service appointment is completed.   \n",
       "1  As soon as customer obtains pictures, potentially tomorrow as suggested by customer.   \n",
       "2           In 3-5 business days, to allow time for the customer's internal discussion.   \n",
       "3                                                      March (or when weather warms up)   \n",
       "4                             On December 18th, prior to the 4-5 PM appointment window.   \n",
       "5                                         By 9 AM on Monday (as promised by the agent).   \n",
       "6                                                    At customer's earliest convenience   \n",
       "7                                        By 9 AM on Monday (as committed by the agent).   \n",
       "8          On December 19th, prior to the technician's arrival, which is after 2:30 PM.   \n",
       "9                                                                Monday morning by 9 AM   \n",
       "\n",
       "  deadline_at  \n",
       "0         NaT  \n",
       "1         NaT  \n",
       "2         NaT  \n",
       "3         NaT  \n",
       "4         NaT  \n",
       "5         NaT  \n",
       "6         NaT  \n",
       "7         NaT  \n",
       "8         NaT  \n",
       "9         NaT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows where parsing failed (deadline_at is null)\n",
    "failed_parses = df[df['deadline_at'].isna()][['customer_id', 'timing_description', 'deadline_at']]\n",
    "print(f\"Rows with parsing failures: {len(failed_parses)}\")\n",
    "print(\"\\nSample parsing failures:\")\n",
    "failed_parses.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with successful parses: 58\n",
      "\n",
      "Sample successful parses:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>timing_description</th>\n",
       "      <th>deadline_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>In 2-3 weeks</td>\n",
       "      <td>2025-12-30 22:26:57.527000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>2025-12-13 17:20:34.622000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>2025-12-13 15:36:17.964000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>today</td>\n",
       "      <td>2025-12-13 07:59:59+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>today</td>\n",
       "      <td>2025-12-13 07:59:59+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>Later today</td>\n",
       "      <td>2025-12-13 07:59:59+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>Immediately after the call, or same day.</td>\n",
       "      <td>2025-12-13 03:44:24.546000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>Immediately after the call.</td>\n",
       "      <td>2025-12-13 03:39:04.907000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>As soon as possible, ideally within the hour, to secure today's appointment.</td>\n",
       "      <td>2025-12-13 03:39:04.907000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3</td>\n",
       "      <td>Immediately / End of business day</td>\n",
       "      <td>2025-12-13 03:09:06.616000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  \\\n",
       "71            3   \n",
       "72            3   \n",
       "73            3   \n",
       "74            3   \n",
       "75            3   \n",
       "76            3   \n",
       "77            3   \n",
       "78            3   \n",
       "79            3   \n",
       "80            3   \n",
       "\n",
       "                                                              timing_description  \\\n",
       "71                                                                  In 2-3 weeks   \n",
       "72                                                                      tomorrow   \n",
       "73                                                                      tomorrow   \n",
       "74                                                                         today   \n",
       "75                                                                         today   \n",
       "76                                                                   Later today   \n",
       "77                                      Immediately after the call, or same day.   \n",
       "78                                                   Immediately after the call.   \n",
       "79  As soon as possible, ideally within the hour, to secure today's appointment.   \n",
       "80                                             Immediately / End of business day   \n",
       "\n",
       "                        deadline_at  \n",
       "71 2025-12-30 22:26:57.527000+00:00  \n",
       "72 2025-12-13 17:20:34.622000+00:00  \n",
       "73 2025-12-13 15:36:17.964000+00:00  \n",
       "74        2025-12-13 07:59:59+00:00  \n",
       "75        2025-12-13 07:59:59+00:00  \n",
       "76        2025-12-13 07:59:59+00:00  \n",
       "77 2025-12-13 03:44:24.546000+00:00  \n",
       "78 2025-12-13 03:39:04.907000+00:00  \n",
       "79 2025-12-13 03:39:04.907000+00:00  \n",
       "80 2025-12-13 03:09:06.616000+00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows where parsing succeeded (deadline_at has value)\n",
    "successful_parses = df[df['deadline_at'].notna()][['customer_id', 'timing_description', 'deadline_at']]\n",
    "print(f\"Rows with successful parses: {len(successful_parses)}\")\n",
    "print(\"\\nSample successful parses:\")\n",
    "successful_parses.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parsers directory does not exist yet: time_parser/parsers\n"
     ]
    }
   ],
   "source": [
    "# Clear parsers directory (start with empty state)\n",
    "parsers_dir = Path(\"time_parser/parsers\")\n",
    "if parsers_dir.exists():\n",
    "    # Remove all Python files except __init__.py\n",
    "    for parser_file in parsers_dir.glob(\"*.py\"):\n",
    "        if parser_file.name != \"__init__.py\":\n",
    "            parser_file.unlink()\n",
    "            print(f\"✓ Removed {parser_file.name}\")\n",
    "    print(f\"✓ Cleared parsers directory: {parsers_dir}\")\n",
    "else:\n",
    "    print(f\"✓ Parsers directory does not exist yet: {parsers_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsers directory: time_parser/parsers\n",
      "Exists: False\n",
      "Parsers directory does not exist yet\n"
     ]
    }
   ],
   "source": [
    "# Show parsers directory (initially empty)\n",
    "from pathlib import Path\n",
    "\n",
    "parsers_dir = Path(\"time_parser/parsers\")\n",
    "print(f\"Parsers directory: {parsers_dir}\")\n",
    "print(f\"Exists: {parsers_dir.exists()}\")\n",
    "\n",
    "if parsers_dir.exists():\n",
    "    parser_files = list(parsers_dir.glob(\"*.py\"))\n",
    "    print(f\"Parser modules: {[f.name for f in parser_files if f.name != '__init__.py']}\")\n",
    "else:\n",
    "    print(\"Parsers directory does not exist yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initial parser:\n",
      "✓ Parsed 'asap': 2025-12-14 00:51:49.688287+00:00\n",
      "✓ Parsed 'now': 2025-12-14 00:51:49.688334+00:00\n",
      "✗ Failed to parse 'tomorrow': Could not parse time expression: tomorrow\n"
     ]
    }
   ],
   "source": [
    "# Create and test initial parser\n",
    "parser = TimeParser()\n",
    "\n",
    "# Test with basic inputs\n",
    "test_inputs = [\"asap\", \"now\", \"tomorrow\"]\n",
    "\n",
    "print(\"Testing initial parser:\")\n",
    "for input_text in test_inputs:\n",
    "    try:\n",
    "        result = parser.parse(input_text)\n",
    "        print(f\"✓ Parsed '{input_text}': {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Failed to parse '{input_text}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Collection\n",
    "\n",
    "Now let's wrap the parser with the exception interceptor to automatically log parsing failures to the error queue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleared existing error queue\n",
      "✓ Parser wrapped with exception interceptor\n"
     ]
    }
   ],
   "source": [
    "# Clean up any existing error queue\n",
    "error_queue_path = Path(\"error_queue.jsonl\")\n",
    "if error_queue_path.exists():\n",
    "    error_queue_path.unlink()\n",
    "    print(\"✓ Cleared existing error queue\")\n",
    "\n",
    "# Wrap parser with exception interceptor\n",
    "wrapped_parse = intercept_parser_errors(\n",
    "    parser,\n",
    "    queue_path=str(error_queue_path),\n",
    ")(parser.parse)\n",
    "\n",
    "print(\"✓ Parser wrapped with exception interceptor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parser with various inputs (errors will be logged):\n",
      "✗ Failed to parse 'tomorrow' (logged to error queue)\n",
      "✗ Failed to parse 'next week' (logged to error queue)\n",
      "✗ Failed to parse 'in 2 days' (logged to error queue)\n",
      "✗ Failed to parse 'Monday morning' (logged to error queue)\n",
      "✗ Failed to parse 'By 9 AM on Monday' (logged to error queue)\n",
      "✗ Failed to parse 'Within 1-2 business days' (logged to error queue)\n",
      "✗ Failed to parse 'After the initial service appointment is completed' (logged to error queue)\n"
     ]
    }
   ],
   "source": [
    "# Test parser with various inputs that will fail\n",
    "test_inputs = [\n",
    "    \"tomorrow\",\n",
    "    \"next week\",\n",
    "    \"in 2 days\",\n",
    "    \"Monday morning\",\n",
    "    \"By 9 AM on Monday\",\n",
    "    \"Within 1-2 business days\",\n",
    "    \"After the initial service appointment is completed\",\n",
    "]\n",
    "\n",
    "print(\"Testing parser with various inputs (errors will be logged):\")\n",
    "for input_text in test_inputs:\n",
    "    try:\n",
    "        result = wrapped_parse(input_text)\n",
    "        print(f\"✓ Parsed '{input_text}': {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Failed to parse '{input_text}' (logged to error queue)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors in queue: 7\n",
      "\n",
      "Sample errors:\n",
      "1. tomorrow\n",
      "2. next week\n",
      "3. in 2 days\n",
      "4. Monday morning\n",
      "5. By 9 AM on Monday\n"
     ]
    }
   ],
   "source": [
    "# Display error queue contents\n",
    "errors = read_error_queue(error_queue_path)\n",
    "print(f\"Total errors in queue: {len(errors)}\")\n",
    "print(\"\\nSample errors:\")\n",
    "for i, error in enumerate(errors[:5]):\n",
    "    print(f\"{i+1}. {error.get('timing_description', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview: The REASON node will cluster these errors by semantic similarity. For example:**\n",
    "- **Relative dates cluster**: \"tomorrow\", \"next week\", \"in 2 days\", \"Monday morning\"\n",
    "- **Specific dates with times cluster**: \"By 9 AM on Monday\"\n",
    "- **Time ranges cluster**: \"Within 1-2 business days\"\n",
    "- **Context-dependent cluster**: \"After the initial service appointment is completed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Activation\n",
    "\n",
    "Now let's activate the coding agent to analyze errors, generate parser modules, and update the parser automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in queue: 7\n",
      "Error threshold: 5\n",
      "✓ Enough errors to activate agent\n"
     ]
    }
   ],
   "source": [
    "# Check error count threshold\n",
    "error_count = get_error_count(error_queue_path)\n",
    "print(f\"Errors in queue: {error_count}\")\n",
    "\n",
    "from coding_agent.config import ERROR_THRESHOLD\n",
    "print(f\"Error threshold: {ERROR_THRESHOLD}\")\n",
    "\n",
    "if error_count >= ERROR_THRESHOLD:\n",
    "    print(\"✓ Enough errors to activate agent\")\n",
    "else:\n",
    "    print(f\"⚠ Need at least {ERROR_THRESHOLD} errors to activate agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NodePrompts created (template user prompts, not formatted)\n",
      "✓ NodeLLMs configured\n",
      "✓ Thread ID: coding_agent_8134fa8f\n"
     ]
    }
   ],
   "source": [
    "# Build NodePrompts\n",
    "node_prompts = build_node_prompts()\n",
    "print(\"✓ NodePrompts created (template user prompts, not formatted)\")\n",
    "\n",
    "# Build NodeLLMs\n",
    "node_llms = NodeLLMs(reason=llm, plan=llm, act=llm, validate=llm)\n",
    "print(\"✓ NodeLLMs configured\")\n",
    "\n",
    "# Generate thread_id\n",
    "thread_id = f\"coding_agent_{uuid.uuid4().hex[:8]}\"\n",
    "print(f\"✓ Thread ID: {thread_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CodingAgentWorkflow initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize CodingAgentWorkflow\n",
    "workflow = CodingAgentWorkflow(\n",
    "    node_llms=node_llms,\n",
    "    node_prompts=node_prompts,  # Template prompts, not formatted\n",
    "    thread_id=thread_id,\n",
    "    error_queue_path=\"error_queue.jsonl\",\n",
    "    parsers_dir=\"time_parser/parsers\",\n",
    "    tests_dir=\"time_parser/tests\",\n",
    "    rate_limiting_config=DEFAULT_RATE_LIMITING_CONFIG,\n",
    "    fail_fast=False,\n",
    "    error_logging=True,\n",
    "    debug_logging=False,\n",
    "    enforce_structured_llm_output=False,  # Must be False for schema=None\n",
    ")\n",
    "\n",
    "print(\"✓ CodingAgentWorkflow initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Initial state created\n"
     ]
    }
   ],
   "source": [
    "# Create initial state\n",
    "initial_state = AnnotationState(\n",
    "    messages=[],\n",
    "    node_output=None,\n",
    "    final_output=None,\n",
    ")\n",
    "\n",
    "print(\"✓ Initial state created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:51:55,942 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running coding agent workflow...\n",
      "This will:\n",
      "  1. REASON: Cluster errors by semantic similarity\n",
      "  2. PLAN: Design code changes and test strategy\n",
      "  3. ACT: Generate parser modules and test files\n",
      "  4. VALIDATE: Run tests and verify all pass\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:52:18,273 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-13 16:52:18,284 - coding_agent.agent - ERROR - REASON node failed: expected string or bytes-like object, got 'list'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/coding_agent/agent.py\", line 257, in _reason_node\n",
      "    parsed_response = self._llm_json_parser.parse_llm_json_extraction_response(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/utils/llm_json_parser.py\", line 75, in parse_llm_json_extraction_response\n",
      "    cleaned: str = self._strip_formatting_wrappers(text=response_content)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/utils/llm_json_parser.py\", line 130, in _strip_formatting_wrappers\n",
      "    text = re.sub(\n",
      "           ^^^^^^^\n",
      "  File \"/Users/alexsherstinsky/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/re/__init__.py\", line 185, in sub\n",
      "    return _compile(pattern, flags).sub(repl, string, count)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'list'\n",
      "2025-12-13 16:52:18,288 - coding_agent.agent - WARNING - REASON node failed: expected string or bytes-like object, got 'list'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Workflow completed!\n",
      "Result keys: ['success', 'processed_clusters', 'errors_removed_count', 'parser_updated', 'tests_passed', 'retry_count', 'message']\n"
     ]
    }
   ],
   "source": [
    "# Run agent workflow\n",
    "print(\"Running coding agent workflow...\")\n",
    "print(\"This will:\")\n",
    "print(\"  1. REASON: Cluster errors by semantic similarity\")\n",
    "print(\"  2. PLAN: Design code changes and test strategy\")\n",
    "print(\"  3. ACT: Generate parser modules and test files\")\n",
    "print(\"  4. VALIDATE: Run tests and verify all pass\")\n",
    "print()\n",
    "\n",
    "result = workflow.run(initial_state=initial_state)\n",
    "\n",
    "print(\"\\n✓ Workflow completed!\")\n",
    "print(f\"Result keys: {list(result.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display agent results\n",
    "print(\"Agent Results:\")\n",
    "print(f\"  Success: {result.get('success', False)}\")\n",
    "print(f\"  Processed clusters: {result.get('processed_clusters', [])}\")\n",
    "print(f\"  Errors removed: {result.get('errors_removed_count', 0)}\")\n",
    "print(f\"  Parser updated: {result.get('parser_updated', False)}\")\n",
    "print(f\"  Tests passed: {result.get('tests_passed', False)}\")\n",
    "print(f\"  Retry count: {result.get('retry_count', 0)}\")\n",
    "print(f\"  Generated modules: {list(result.get('generated_cluster_modules', {}).keys())}\")\n",
    "print(f\"  Generated test files: {list(result.get('generated_test_files', {}).keys())}\")\n",
    "\n",
    "if result.get('message'):\n",
    "    print(f\"  Message: {result['message']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Verification\n",
    "\n",
    "Let's verify that the parser now works with previously failing inputs and check the test results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload parser after agent update\n",
    "parser = reload_parser(\"time_parser/parsers\")\n",
    "print(\"✓ Parser reloaded with updated cluster modules\")\n",
    "\n",
    "# Show updated parsers directory\n",
    "parsers_dir = Path(\"time_parser/parsers\")\n",
    "if parsers_dir.exists():\n",
    "    parser_files = list(parsers_dir.glob(\"*.py\"))\n",
    "    print(f\"Parser modules: {[f.name for f in parser_files if f.name != '__init__.py']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parser with previously failing inputs\n",
    "previously_failing = [\n",
    "    \"tomorrow\",\n",
    "    \"next week\",\n",
    "    \"in 2 days\",\n",
    "    \"Monday morning\",\n",
    "]\n",
    "\n",
    "print(\"Testing parser with previously failing inputs:\")\n",
    "for input_text in previously_failing:\n",
    "    try:\n",
    "        result = parser.parse(input_text)\n",
    "        print(f\"✓ Parsed '{input_text}': {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Still failed to parse '{input_text}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pytest and display results\n",
    "test_results = run_pytest(\"time_parser/tests\", verbose=True)\n",
    "\n",
    "print(f\"All tests passed: {test_results['all_passed']}\")\n",
    "print(f\"Return code: {test_results['returncode']}\")\n",
    "print(f\"\\nTest output:\\n{test_results['test_output']}\")\n",
    "\n",
    "if test_results['test_errors']:\n",
    "    print(f\"\\nTest errors:\\n{test_results['test_errors']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show updated error queue (should have fewer errors)\n",
    "remaining_errors = read_error_queue(error_queue_path)\n",
    "print(f\"Remaining errors in queue: {len(remaining_errors)}\")\n",
    "print(f\"Errors removed: {result.get('errors_removed_count', 0)}\")\n",
    "\n",
    "if remaining_errors:\n",
    "    print(\"\\nRemaining errors (not yet processed):\")\n",
    "    for i, error in enumerate(remaining_errors[:5]):\n",
    "        print(f\"  {i+1}. {error.get('timing_description', 'N/A')}\")\n",
    "else:\n",
    "    print(\"\\n✓ All errors have been processed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Production Data Validation\n",
    "\n",
    "Now let's validate the system with real production data from the fixture file. This demonstrates that the self-healing parser works not just with controlled test inputs, but also with actual production failures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear error queue again for production data validation\n",
    "if error_queue_path.exists():\n",
    "    error_queue_path.unlink()\n",
    "    print(\"✓ Cleared error queue for production data validation\")\n",
    "else:\n",
    "    print(\"✓ Error queue already empty\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fixture data and populate error queue with real production failures\n",
    "from coding_agent.error_queue import append_error_to_queue\n",
    "\n",
    "# Use project_root from cell 1 for fixture path\n",
    "fixture_path = project_root / \"tests\" / \"fixtures\" / \"follow_up_tasks_202512121435.jsonl\"\n",
    "if not fixture_path.exists():\n",
    "    raise FileNotFoundError(f\"Fixture file not found: {fixture_path}\")\n",
    "df_production = pd.read_json(str(fixture_path), lines=True)\n",
    "\n",
    "# Filter for rows where deadline_at is null (parsing failures)\n",
    "failed_parses_production = df_production[df_production['deadline_at'].isna()]\n",
    "\n",
    "print(f\"Total rows in fixture: {len(df_production)}\")\n",
    "print(f\"Rows with parsing failures: {len(failed_parses_production)}\")\n",
    "\n",
    "# Add production errors to error queue\n",
    "errors_added = 0\n",
    "for _, row in failed_parses_production.iterrows():\n",
    "    error_entry = {\n",
    "        \"customer_id\": row.get('customer_id'),\n",
    "        \"deadline_at\": None,\n",
    "        \"timing_description\": row.get('timing_description'),\n",
    "        \"auxiliary_pretty\": row.get('auxiliary_pretty', '{}'),\n",
    "    }\n",
    "    \n",
    "    # Validate timing_description is a non-empty string\n",
    "    timing_desc = error_entry.get('timing_description', '')\n",
    "    if isinstance(timing_desc, str) and timing_desc.strip():\n",
    "        append_error_to_queue(str(error_queue_path), error_entry)\n",
    "        errors_added += 1\n",
    "\n",
    "print(f\"✓ Added {errors_added} production errors to error queue\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample production errors in queue\n",
    "production_errors = read_error_queue(error_queue_path)\n",
    "print(f\"Total production errors in queue: {len(production_errors)}\")\n",
    "print(\"\\nSample production errors:\")\n",
    "for i, error in enumerate(production_errors[:10]):\n",
    "    timing_desc = error.get('timing_description', 'N/A')\n",
    "    print(f\"  {i+1}. {timing_desc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have enough errors to run the agent\n",
    "production_error_count = get_error_count(error_queue_path)\n",
    "print(f\"Production errors in queue: {production_error_count}\")\n",
    "print(f\"Error threshold: {ERROR_THRESHOLD}\")\n",
    "\n",
    "if production_error_count >= ERROR_THRESHOLD:\n",
    "    print(\"✓ Enough production errors to activate agent\")\n",
    "    print(\"\\nNote: You can run the agent workflow again to process these production errors.\")\n",
    "    print(\"The workflow would cluster these real production patterns and generate\")\n",
    "    print(\"parser modules to handle them, just as it did with the controlled test inputs.\")\n",
    "else:\n",
    "    print(f\"⚠ Need at least {ERROR_THRESHOLD} errors to activate agent\")\n",
    "    print(f\"   (Current: {production_error_count})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Run Agent on Production Data**\n",
    "\n",
    "The cell below can be executed to process the production errors through the agent workflow. This demonstrates the full cycle with real production data. (You can skip this if you've already demonstrated the workflow above.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run agent workflow on production errors\n",
    "# Uncomment the code below to process production errors through the agent\n",
    "\n",
    "# if production_error_count >= ERROR_THRESHOLD:\n",
    "#     # Generate new thread_id for this run\n",
    "#     production_thread_id = f\"coding_agent_production_{uuid.uuid4().hex[:8]}\"\n",
    "#     \n",
    "#     # Initialize workflow (reuse same configuration)\n",
    "#     production_workflow = CodingAgentWorkflow(\n",
    "#         node_llms=node_llms,\n",
    "#         node_prompts=node_prompts,\n",
    "#         thread_id=production_thread_id,\n",
    "#         error_queue_path=\"error_queue.jsonl\",\n",
    "#         parsers_dir=\"time_parser/parsers\",\n",
    "#         tests_dir=\"time_parser/tests\",\n",
    "#         rate_limiting_config=DEFAULT_RATE_LIMITING_CONFIG,\n",
    "#         fail_fast=False,\n",
    "#         error_logging=True,\n",
    "#         debug_logging=False,\n",
    "#         enforce_structured_llm_output=False,\n",
    "#     )\n",
    "#     \n",
    "#     # Create initial state\n",
    "#     production_initial_state = AnnotationState(\n",
    "#         messages=[],\n",
    "#         node_output=None,\n",
    "#         final_output=None,\n",
    "#     )\n",
    "#     \n",
    "#     # Run workflow\n",
    "#     print(\"Running agent workflow on production errors...\")\n",
    "#     production_result = production_workflow.run(initial_state=production_initial_state)\n",
    "#     \n",
    "#     print(\"\\n✓ Production workflow completed!\")\n",
    "#     print(f\"Success: {production_result.get('success', False)}\")\n",
    "#     print(f\"Processed clusters: {production_result.get('processed_clusters', [])}\")\n",
    "#     print(f\"Errors removed: {production_result.get('errors_removed_count', 0)}\")\n",
    "#     \n",
    "#     # Reload parser and test with production patterns\n",
    "#     parser = reload_parser(\"time_parser/parsers\")\n",
    "#     print(\"\\n✓ Parser reloaded with production-generated modules\")\n",
    "# else:\n",
    "#     print(\"Not enough errors to run agent workflow\")\n",
    "\n",
    "print(\"(Cell is commented out - uncomment to run agent on production data)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The self-healing time parser system has successfully:\n",
    "1. ✅ Collected parsing failures in the error queue\n",
    "2. ✅ Clustered errors by semantic similarity\n",
    "3. ✅ Generated parser modules for each error cluster\n",
    "4. ✅ Created comprehensive test files\n",
    "5. ✅ Validated all tests pass\n",
    "6. ✅ Updated the parser with new capabilities\n",
    "7. ✅ Removed processed errors from the queue\n",
    "\n",
    "The parser can now handle previously failing time expressions automatically!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
