{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Healing Time Parser Demo\n",
    "\n",
    "This notebook demonstrates the self-healing time parser system that uses an LLM-based coding agent to automatically update parsing logic when encountering new time expression patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025\n",
      "Current working directory: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/notebooks\n",
      "Python executable: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/.venv/bin/python3\n",
      "Python path includes project root: True\n",
      "✓ coding_agent module found at: /Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/coding_agent/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Path setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root: the directory that contains notebooks/ as a subdirectory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Start from current directory and walk up until we find a directory with notebooks/ subdirectory\n",
    "project_root = None\n",
    "current = cwd\n",
    "while current != current.parent:  # Stop at filesystem root\n",
    "    if (current / \"notebooks\").exists() and (current / \"notebooks\").is_dir():\n",
    "        project_root = current\n",
    "        break\n",
    "    current = current.parent\n",
    "\n",
    "# If not found, fallback to current directory\n",
    "if project_root is None:\n",
    "    project_root = cwd\n",
    "    print(f\"⚠ Warning: Could not find project root (directory with notebooks/ subdirectory)\")\n",
    "    print(f\"   Using current directory as fallback: {project_root}\")\n",
    "\n",
    "# Add project root to path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python path includes project root: {str(project_root) in sys.path}\")\n",
    "\n",
    "# Verify coding_agent can be found\n",
    "try:\n",
    "    import coding_agent\n",
    "    print(f\"✓ coding_agent module found at: {coding_agent.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ coding_agent module not found: {e}\")\n",
    "    print(f\"  Please ensure you're using the correct Python environment where the package is installed.\")\n",
    "    print(f\"  Try: uv run jupyter notebook notebooks/demo.ipynb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n",
      "✓ Pandas display options configured for full column width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/coding_agent/llms.py:13: UserWarning: Field name \"validate\" in \"NodeLLMs\" shadows an attribute in parent \"BaseModel\"\n",
      "  class NodeLLMs(BaseModel):\n",
      "/Users/alexsherstinsky/Development/MustExist/ConvoScience/AGI_HOUSE_GEMINI_3_HACKATHON_12132025/agi_house_gemini_3_hackathon_12132025/coding_agent/prompts.py:19: UserWarning: Field name \"validate\" in \"NodePrompts\" shadows an attribute in parent \"BaseModel\"\n",
      "  class NodePrompts(BaseModel):\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from coding_agent.agent import CodingAgentWorkflow\n",
    "from coding_agent.base import (\n",
    "    AnnotationState,\n",
    "    DEFAULT_RATE_LIMITING_CONFIG,\n",
    ")\n",
    "from coding_agent.error_queue import get_error_count, read_error_queue\n",
    "from coding_agent.llms import NodeLLMs\n",
    "from coding_agent.prompts import build_node_prompts\n",
    "from coding_agent.reloader import reload_parser\n",
    "from coding_agent.test_runner import run_pytest\n",
    "from time_parser import TimeParser\n",
    "from time_parser.wrapper import intercept_parser_errors\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "\n",
    "# Configure pandas display options\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Show full width of each column\n",
    "pd.set_option('display.width', None)  # Auto-detect terminal width\n",
    "pd.set_option('display.max_rows', 100)  # Show up to 100 rows (adjust as needed)\n",
    "\n",
    "print(\"✓ Pandas display options configured for full column width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logging configured (DEBUG level - will show LLM input/output when debug_logging=True)\n"
     ]
    }
   ],
   "source": [
    "# Logging configuration\n",
    "# Set to DEBUG to see LLM input/output when debug_logging=True in workflow\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"✓ Logging configured (DEBUG level - will show LLM input/output when debug_logging=True)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using gemini-3\n",
      "✓ LLM initialized: gemini-3\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemini LLM\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY environment variable not set\")\n",
    "\n",
    "# Try gemini-3\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-3-pro-preview\",\n",
    "        google_api_key=api_key,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=8192,\n",
    "    )\n",
    "    print(\"✓ Using gemini-3\")\n",
    "    print(f\"✓ LLM initialized: gemini-3\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to initialize gemini-3: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Demonstration\n",
    "\n",
    "Let's first examine the problem we're trying to solve - some timing descriptions fail to parse while others succeed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 129\n",
      "Columns: ['customer_id', 'deadline_at', 'timing_description', 'auxiliary_pretty']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>deadline_at</th>\n",
       "      <th>timing_description</th>\n",
       "      <th>auxiliary_pretty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>After the initial service appointment is completed.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: After the initial service appointment is completed.\",\\n        \"original_timing\": \"After the initial service appointment is completed.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"After the initial service appointment is completed.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>As soon as customer obtains pictures, potentially tomorrow as suggested by customer.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>In 3-5 business days, to allow time for the customer's internal discussion.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>March (or when weather warms up)</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: March (or when weather warms up)\",\\n        \"original_timing\": \"March (or when weather warms up)\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"March (or when weather warms up)\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>On December 18th, prior to the 4-5 PM appointment window.</td>\n",
       "      <td>{\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"parsed_timestamp\": null\\n    }\\n}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id deadline_at  \\\n",
       "0            3         NaT   \n",
       "1            3         NaT   \n",
       "2            3         NaT   \n",
       "3            3         NaT   \n",
       "4            3         NaT   \n",
       "\n",
       "                                                                     timing_description  \\\n",
       "0                                   After the initial service appointment is completed.   \n",
       "1  As soon as customer obtains pictures, potentially tomorrow as suggested by customer.   \n",
       "2           In 3-5 business days, to allow time for the customer's internal discussion.   \n",
       "3                                                      March (or when weather warms up)   \n",
       "4                             On December 18th, prior to the 4-5 PM appointment window.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         auxiliary_pretty  \n",
       "0                                                                                                     {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: After the initial service appointment is completed.\",\\n        \"original_timing\": \"After the initial service appointment is completed.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"After the initial service appointment is completed.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "1  {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"As soon as customer obtains pictures, potentially tomorrow as suggested by customer.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "2                             {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"In 3-5 business days, to allow time for the customer's internal discussion.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "3                                                                                                                                                              {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: March (or when weather warms up)\",\\n        \"original_timing\": \"March (or when weather warms up)\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"March (or when weather warms up)\",\\n        \"parsed_timestamp\": null\\n    }\\n}  \n",
       "4                                                                                   {\\n    \"parsing_error\": {\\n        \"error_type\": \"parsing_failed\",\\n        \"error_message\": \"Could not parse timing description: On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\"\\n    },\\n    \"deadline_parsing\": {\\n        \"timezone_used\": \"UTC\",\\n        \"parsing_method\": \"fallback\",\\n        \"original_timing\": \"On December 18th, prior to the 4-5 PM appointment window.\",\\n        \"parsed_timestamp\": null\\n    }\\n}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load fixture file (use project_root from cell 1)\n",
    "fixture_path = project_root / \"tests\" / \"fixtures\" / \"follow_up_tasks_202512121435.jsonl\"\n",
    "if not fixture_path.exists():\n",
    "    raise FileNotFoundError(f\"Fixture file not found: {fixture_path}\")\n",
    "df = pd.read_json(str(fixture_path), lines=True)\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with parsing failures: 71\n",
      "\n",
      "Sample parsing failures:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>timing_description</th>\n",
       "      <th>deadline_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>After the initial service appointment is completed.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>As soon as customer obtains pictures, potentially tomorrow as suggested by customer.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>In 3-5 business days, to allow time for the customer's internal discussion.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>March (or when weather warms up)</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>On December 18th, prior to the 4-5 PM appointment window.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>By 9 AM on Monday (as promised by the agent).</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>At customer's earliest convenience</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>By 9 AM on Monday (as committed by the agent).</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>On December 19th, prior to the technician's arrival, which is after 2:30 PM.</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Monday morning by 9 AM</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  \\\n",
       "0            3   \n",
       "1            3   \n",
       "2            3   \n",
       "3            3   \n",
       "4            3   \n",
       "5            3   \n",
       "6            3   \n",
       "7            3   \n",
       "8            3   \n",
       "9            3   \n",
       "\n",
       "                                                                     timing_description  \\\n",
       "0                                   After the initial service appointment is completed.   \n",
       "1  As soon as customer obtains pictures, potentially tomorrow as suggested by customer.   \n",
       "2           In 3-5 business days, to allow time for the customer's internal discussion.   \n",
       "3                                                      March (or when weather warms up)   \n",
       "4                             On December 18th, prior to the 4-5 PM appointment window.   \n",
       "5                                         By 9 AM on Monday (as promised by the agent).   \n",
       "6                                                    At customer's earliest convenience   \n",
       "7                                        By 9 AM on Monday (as committed by the agent).   \n",
       "8          On December 19th, prior to the technician's arrival, which is after 2:30 PM.   \n",
       "9                                                                Monday morning by 9 AM   \n",
       "\n",
       "  deadline_at  \n",
       "0         NaT  \n",
       "1         NaT  \n",
       "2         NaT  \n",
       "3         NaT  \n",
       "4         NaT  \n",
       "5         NaT  \n",
       "6         NaT  \n",
       "7         NaT  \n",
       "8         NaT  \n",
       "9         NaT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows where parsing failed (deadline_at is null)\n",
    "failed_parses = df[df['deadline_at'].isna()][['customer_id', 'timing_description', 'deadline_at']]\n",
    "print(f\"Rows with parsing failures: {len(failed_parses)}\")\n",
    "print(\"\\nSample parsing failures:\")\n",
    "failed_parses.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with successful parses: 58\n",
      "\n",
      "Sample successful parses:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>timing_description</th>\n",
       "      <th>deadline_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>In 2-3 weeks</td>\n",
       "      <td>2025-12-30 22:26:57.527000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>2025-12-13 17:20:34.622000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>2025-12-13 15:36:17.964000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>today</td>\n",
       "      <td>2025-12-13 07:59:59+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>today</td>\n",
       "      <td>2025-12-13 07:59:59+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>Later today</td>\n",
       "      <td>2025-12-13 07:59:59+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>Immediately after the call, or same day.</td>\n",
       "      <td>2025-12-13 03:44:24.546000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>Immediately after the call.</td>\n",
       "      <td>2025-12-13 03:39:04.907000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>As soon as possible, ideally within the hour, to secure today's appointment.</td>\n",
       "      <td>2025-12-13 03:39:04.907000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3</td>\n",
       "      <td>Immediately / End of business day</td>\n",
       "      <td>2025-12-13 03:09:06.616000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  \\\n",
       "71            3   \n",
       "72            3   \n",
       "73            3   \n",
       "74            3   \n",
       "75            3   \n",
       "76            3   \n",
       "77            3   \n",
       "78            3   \n",
       "79            3   \n",
       "80            3   \n",
       "\n",
       "                                                              timing_description  \\\n",
       "71                                                                  In 2-3 weeks   \n",
       "72                                                                      tomorrow   \n",
       "73                                                                      tomorrow   \n",
       "74                                                                         today   \n",
       "75                                                                         today   \n",
       "76                                                                   Later today   \n",
       "77                                      Immediately after the call, or same day.   \n",
       "78                                                   Immediately after the call.   \n",
       "79  As soon as possible, ideally within the hour, to secure today's appointment.   \n",
       "80                                             Immediately / End of business day   \n",
       "\n",
       "                        deadline_at  \n",
       "71 2025-12-30 22:26:57.527000+00:00  \n",
       "72 2025-12-13 17:20:34.622000+00:00  \n",
       "73 2025-12-13 15:36:17.964000+00:00  \n",
       "74        2025-12-13 07:59:59+00:00  \n",
       "75        2025-12-13 07:59:59+00:00  \n",
       "76        2025-12-13 07:59:59+00:00  \n",
       "77 2025-12-13 03:44:24.546000+00:00  \n",
       "78 2025-12-13 03:39:04.907000+00:00  \n",
       "79 2025-12-13 03:39:04.907000+00:00  \n",
       "80 2025-12-13 03:09:06.616000+00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows where parsing succeeded (deadline_at has value)\n",
    "successful_parses = df[df['deadline_at'].notna()][['customer_id', 'timing_description', 'deadline_at']]\n",
    "print(f\"Rows with successful parses: {len(successful_parses)}\")\n",
    "print(\"\\nSample successful parses:\")\n",
    "successful_parses.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parsers directory does not exist yet: time_parser/parsers\n"
     ]
    }
   ],
   "source": [
    "# Clear parsers directory (start with empty state)\n",
    "parsers_dir = Path(\"time_parser/parsers\")\n",
    "if parsers_dir.exists():\n",
    "    # Remove all Python files except __init__.py\n",
    "    for parser_file in parsers_dir.glob(\"*.py\"):\n",
    "        if parser_file.name != \"__init__.py\":\n",
    "            parser_file.unlink()\n",
    "            print(f\"✓ Removed {parser_file.name}\")\n",
    "    print(f\"✓ Cleared parsers directory: {parsers_dir}\")\n",
    "else:\n",
    "    print(f\"✓ Parsers directory does not exist yet: {parsers_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsers directory: time_parser/parsers\n",
      "Exists: False\n",
      "Parsers directory does not exist yet\n"
     ]
    }
   ],
   "source": [
    "# Show parsers directory (initially empty)\n",
    "from pathlib import Path\n",
    "\n",
    "parsers_dir = Path(\"time_parser/parsers\")\n",
    "print(f\"Parsers directory: {parsers_dir}\")\n",
    "print(f\"Exists: {parsers_dir.exists()}\")\n",
    "\n",
    "if parsers_dir.exists():\n",
    "    parser_files = list(parsers_dir.glob(\"*.py\"))\n",
    "    print(f\"Parser modules: {[f.name for f in parser_files if f.name != '__init__.py']}\")\n",
    "else:\n",
    "    print(\"Parsers directory does not exist yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initial parser:\n",
      "✓ Parsed 'asap': 2025-12-14 01:05:43.238238+00:00\n",
      "✓ Parsed 'now': 2025-12-14 01:05:43.238296+00:00\n",
      "✗ Failed to parse 'tomorrow': Could not parse time expression: tomorrow\n"
     ]
    }
   ],
   "source": [
    "# Create and test initial parser\n",
    "parser = TimeParser()\n",
    "\n",
    "# Test with basic inputs\n",
    "test_inputs = [\"asap\", \"now\", \"tomorrow\"]\n",
    "\n",
    "print(\"Testing initial parser:\")\n",
    "for input_text in test_inputs:\n",
    "    try:\n",
    "        result = parser.parse(input_text)\n",
    "        print(f\"✓ Parsed '{input_text}': {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Failed to parse '{input_text}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Collection\n",
    "\n",
    "Now let's wrap the parser with the exception interceptor to automatically log parsing failures to the error queue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleared existing error queue\n",
      "✓ Parser wrapped with exception interceptor\n"
     ]
    }
   ],
   "source": [
    "# Clean up any existing error queue\n",
    "error_queue_path = Path(\"error_queue.jsonl\")\n",
    "if error_queue_path.exists():\n",
    "    error_queue_path.unlink()\n",
    "    print(\"✓ Cleared existing error queue\")\n",
    "\n",
    "# Wrap parser with exception interceptor\n",
    "wrapped_parse = intercept_parser_errors(\n",
    "    parser,\n",
    "    queue_path=str(error_queue_path),\n",
    ")(parser.parse)\n",
    "\n",
    "print(\"✓ Parser wrapped with exception interceptor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parser with various inputs (errors will be logged):\n",
      "✗ Failed to parse 'tomorrow' (logged to error queue)\n",
      "✗ Failed to parse 'next week' (logged to error queue)\n",
      "✗ Failed to parse 'in 2 days' (logged to error queue)\n",
      "✗ Failed to parse 'Monday morning' (logged to error queue)\n",
      "✗ Failed to parse 'By 9 AM on Monday' (logged to error queue)\n",
      "✗ Failed to parse 'Within 1-2 business days' (logged to error queue)\n",
      "✗ Failed to parse 'After the initial service appointment is completed' (logged to error queue)\n"
     ]
    }
   ],
   "source": [
    "# Test parser with various inputs that will fail\n",
    "test_inputs = [\n",
    "    \"tomorrow\",\n",
    "    \"next week\",\n",
    "    \"in 2 days\",\n",
    "    \"Monday morning\",\n",
    "    \"By 9 AM on Monday\",\n",
    "    \"Within 1-2 business days\",\n",
    "    \"After the initial service appointment is completed\",\n",
    "]\n",
    "\n",
    "print(\"Testing parser with various inputs (errors will be logged):\")\n",
    "for input_text in test_inputs:\n",
    "    try:\n",
    "        result = wrapped_parse(input_text)\n",
    "        print(f\"✓ Parsed '{input_text}': {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Failed to parse '{input_text}' (logged to error queue)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors in queue: 7\n",
      "\n",
      "Sample errors:\n",
      "1. tomorrow\n",
      "2. next week\n",
      "3. in 2 days\n",
      "4. Monday morning\n",
      "5. By 9 AM on Monday\n"
     ]
    }
   ],
   "source": [
    "# Display error queue contents\n",
    "errors = read_error_queue(error_queue_path)\n",
    "print(f\"Total errors in queue: {len(errors)}\")\n",
    "print(\"\\nSample errors:\")\n",
    "for i, error in enumerate(errors[:5]):\n",
    "    print(f\"{i+1}. {error.get('timing_description', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview: The REASON node will cluster these errors by semantic similarity. For example:**\n",
    "- **Relative dates cluster**: \"tomorrow\", \"next week\", \"in 2 days\", \"Monday morning\"\n",
    "- **Specific dates with times cluster**: \"By 9 AM on Monday\"\n",
    "- **Time ranges cluster**: \"Within 1-2 business days\"\n",
    "- **Context-dependent cluster**: \"After the initial service appointment is completed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Activation\n",
    "\n",
    "Now let's activate the coding agent to analyze errors, generate parser modules, and update the parser automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in queue: 7\n",
      "Error threshold: 5\n",
      "✓ Enough errors to activate agent\n"
     ]
    }
   ],
   "source": [
    "# Check error count threshold\n",
    "error_count = get_error_count(error_queue_path)\n",
    "print(f\"Errors in queue: {error_count}\")\n",
    "\n",
    "from coding_agent.config import ERROR_THRESHOLD\n",
    "print(f\"Error threshold: {ERROR_THRESHOLD}\")\n",
    "\n",
    "if error_count >= ERROR_THRESHOLD:\n",
    "    print(\"✓ Enough errors to activate agent\")\n",
    "else:\n",
    "    print(f\"⚠ Need at least {ERROR_THRESHOLD} errors to activate agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NodePrompts created (template user prompts, not formatted)\n",
      "✓ NodeLLMs configured\n",
      "✓ Thread ID: coding_agent_e0f4487c\n"
     ]
    }
   ],
   "source": [
    "# Build NodePrompts\n",
    "node_prompts = build_node_prompts()\n",
    "print(\"✓ NodePrompts created (template user prompts, not formatted)\")\n",
    "\n",
    "# Build NodeLLMs\n",
    "node_llms = NodeLLMs(reason=llm, plan=llm, act=llm, validate=llm)\n",
    "print(\"✓ NodeLLMs configured\")\n",
    "\n",
    "# Generate thread_id\n",
    "thread_id = f\"coding_agent_{uuid.uuid4().hex[:8]}\"\n",
    "print(f\"✓ Thread ID: {thread_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CodingAgentWorkflow initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize CodingAgentWorkflow\n",
    "workflow = CodingAgentWorkflow(\n",
    "    node_llms=node_llms,\n",
    "    node_prompts=node_prompts,  # Template prompts, not formatted\n",
    "    thread_id=thread_id,\n",
    "    error_queue_path=\"error_queue.jsonl\",\n",
    "    parsers_dir=\"time_parser/parsers\",\n",
    "    tests_dir=\"time_parser/tests\",\n",
    "    rate_limiting_config=DEFAULT_RATE_LIMITING_CONFIG,\n",
    "    fail_fast=False,\n",
    "    error_logging=True,\n",
    "    debug_logging=True,\n",
    "    enforce_structured_llm_output=False,  # Must be False for schema=None\n",
    ")\n",
    "\n",
    "print(\"✓ CodingAgentWorkflow initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Initial state created\n"
     ]
    }
   ],
   "source": [
    "# Create initial state\n",
    "initial_state = AnnotationState(\n",
    "    messages=[],\n",
    "    node_output=None,\n",
    "    final_output=None,\n",
    ")\n",
    "\n",
    "print(\"✓ Initial state created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 17:05:51,513 - utils.llm_helpers - DEBUG - \n",
      "================================================================================\n",
      "[Node=Node=reason] LLM Input:\n",
      "----------------------------------------\n",
      "System Prompt:\n",
      "\n",
      "You are an expert in natural language time expression parsing and pattern recognition.\n",
      "\n",
      "Your task is to analyze a collection of parsing errors and cluster them into groups of similar patterns. Each cluster represents a class of time expressions that can be handled by a single parsing module.\n",
      "\n",
      "## Context\n",
      "\n",
      "We are building a self-healing time parser system. When the parser encounters time expressions it cannot parse, those errors are logged to a queue file. Your job is to identify common patterns among these errors so that we can generate efficient parsing code that handles multiple similar cases at once.\n",
      "\n",
      "## Clustering Principles\n",
      "\n",
      "1. **Semantic Similarity**: Group errors that represent similar time expression patterns, even if the exact wording differs\n",
      "   - Example: \"tomorrow\", \"next week\", \"in 2 days\" → all relative date expressions\n",
      "   - Example: \"By 9 AM on Monday\", \"Monday morning by 9 AM\" → both specific dates with times\n",
      "\n",
      "2. **Parsing Approach**: Errors that would be solved by similar parsing logic should be clustered together\n",
      "   - Example: \"Within 1-2 business days\", \"In 3-5 business days\" → both time ranges with business day modifiers\n",
      "\n",
      "3. **Distinguish Parsable from Unparseable**:\n",
      "   - **Parsable**: Errors that can be solved with additional parsing logic (e.g., relative dates, specific dates, time ranges)\n",
      "   - **Context-Dependent**: Errors that require external context (e.g., \"After service completion\", \"When customer is ready\") - attempt to cluster these but note they may be challenging\n",
      "   - **Ambiguous/Vague**: Errors that cannot be parsed without additional information (e.g., \"At customer's earliest convenience\") - cluster separately and note as potentially unparseable\n",
      "\n",
      "4. **Cluster Naming**: Use descriptive, lowercase_with_underscores names for cluster IDs (e.g., \"relative_dates\", \"specific_dates_with_times\", \"time_ranges\", \"context_dependent\")\n",
      "\n",
      "## Output Requirements\n",
      "\n",
      "You must output a JSON object with the following structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"clusters\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_dates\",\n",
      "            \"error_indices\": [0, 1, 5, 12],\n",
      "            \"commonality\": \"relative date expressions without specific times\",\n",
      "            \"examples\": [\"tomorrow\", \"next week\", \"in 2 days\", \"Monday morning\"],\n",
      "            \"suggested_approach\": \"Use dateutil.relativedelta and datetime arithmetic\",\n",
      "            \"parsability\": \"parsable\",\n",
      "            \"error_count\": 4\n",
      "        },\n",
      "        {\n",
      "            \"cluster_id\": \"context_dependent\",\n",
      "            \"error_indices\": [2, 8, 15],\n",
      "            \"commonality\": \"requires external context or event completion\",\n",
      "            \"examples\": [\"After service completion\", \"When customer is ready\", \"After taking photographs\"],\n",
      "            \"suggested_approach\": \"May be unparseable - attempt with smart defaults or skip\",\n",
      "            \"parsability\": \"context_dependent\",\n",
      "            \"error_count\": 3\n",
      "        }\n",
      "    ],\n",
      "    \"selected_clusters\": [\"relative_dates\", \"specific_dates_with_times\", \"time_ranges\"],\n",
      "    \"total_errors_analyzed\": 129,\n",
      "    \"total_clusters_identified\": 8,\n",
      "    \"clusters_selected_count\": 5\n",
      "}\n",
      "```\n",
      "\n",
      "**Field Descriptions:**\n",
      "- `clusters`: Array of all identified clusters\n",
      "  - `cluster_id`: Unique identifier (lowercase_with_underscores, used as module filename)\n",
      "  - `error_indices`: List of error indices from the input array (0-based)\n",
      "  - `commonality`: Brief description of what makes these errors similar\n",
      "  - `examples`: 3-5 example timing_description strings from this cluster\n",
      "  - `suggested_approach`: High-level approach for parsing this cluster\n",
      "  - `parsability`: One of \"parsable\", \"context_dependent\", or \"ambiguous\"\n",
      "  - `error_count`: Number of errors in this cluster\n",
      "- `selected_clusters`: List of cluster_ids selected for processing (up to 5, prioritize parsable clusters)\n",
      "- `total_errors_analyzed`: Total number of errors in the input\n",
      "- `total_clusters_identified`: Total number of clusters found\n",
      "- `clusters_selected_count`: Number of clusters selected (should match length of selected_clusters)\n",
      "\n",
      "## Selection Criteria\n",
      "\n",
      "When selecting clusters for processing (up to 5):\n",
      "1. **Prioritize parsable clusters** over context-dependent or ambiguous ones\n",
      "2. **Prioritize larger clusters** (more errors per cluster = better efficiency)\n",
      "3. **Prioritize common patterns** (relative dates, specific dates, time ranges are common)\n",
      "4. **Balance diversity** - select clusters that represent different parsing challenges\n",
      "\n",
      "## Important Notes\n",
      "\n",
      "- Each error index should appear in exactly one cluster\n",
      "- Cluster IDs must be valid Python module names (lowercase, underscores, no spaces or special chars)\n",
      "- Focus on identifying patterns that can be solved with regex, dateutil, or datetime arithmetic\n",
      "- Some errors may be inherently unparseable - that's acceptable, but cluster them separately\n",
      "- The goal is to generate efficient code that handles multiple similar cases, not one-off solutions\n",
      "\n",
      "----------------------------------------\n",
      "User Prompt:\n",
      "\n",
      "Error Queue File Contents:\n",
      "\n",
      "{\"customer_id\": null, \"deadline_at\": null, \"timing_description\": \"tomorrow\", \"auxiliary_pretty\": \"{\\\"parsing_error\\\": {\\\"error_type\\\": \\\"parsing_failed\\\", \\\"error_message\\\": \\\"Could not parse timing description: tomorrow\\\", \\\"original_timing\\\": \\\"tomorrow\\\", \\\"exception_type\\\": \\\"ValueError\\\", \\\"exception_message\\\": \\\"Could not parse time expression: tomorrow\\\"}, \\\"deadline_parsing\\\": {\\\"timezone_used\\\": \\\"UTC\\\", \\\"parsing_method\\\": \\\"fallback\\\", \\\"original_timing\\\": \\\"tomorrow\\\", \\\"parsed_timestamp\\\": null}}\"}\n",
      "{\"customer_id\": null, \"deadline_at\": null, \"timing_description\": \"next week\", \"auxiliary_pretty\": \"{\\\"parsing_error\\\": {\\\"error_type\\\": \\\"parsing_failed\\\", \\\"error_message\\\": \\\"Could not parse timing description: next week\\\", \\\"original_timing\\\": \\\"next week\\\", \\\"exception_type\\\": \\\"ValueError\\\", \\\"exception_message\\\": \\\"Could not parse time expression: next week\\\"}, \\\"deadline_parsing\\\": {\\\"timezone_used\\\": \\\"UTC\\\", \\\"parsing_method\\\": \\\"fallback\\\", \\\"original_timing\\\": \\\"next week\\\", \\\"parsed_timestamp\\\": null}}\"}\n",
      "{\"customer_id\": null, \"deadline_at\": null, \"timing_description\": \"in 2 days\", \"auxiliary_pretty\": \"{\\\"parsing_error\\\": {\\\"error_type\\\": \\\"parsing_failed\\\", \\\"error_message\\\": \\\"Could not parse timing description: in 2 days\\\", \\\"original_timing\\\": \\\"in 2 days\\\", \\\"exception_type\\\": \\\"ValueError\\\", \\\"exception_message\\\": \\\"Could not parse time expression: in 2 days\\\"}, \\\"deadline_parsing\\\": {\\\"timezone_used\\\": \\\"UTC\\\", \\\"parsing_method\\\": \\\"fallback\\\", \\\"original_timing\\\": \\\"in 2 days\\\", \\\"parsed_timestamp\\\": null}}\"}\n",
      "{\"customer_id\": null, \"deadline_at\": null, \"timing_description\": \"Monday morning\", \"auxiliary_pretty\": \"{\\\"parsing_error\\\": {\\\"error_type\\\": \\\"parsing_failed\\\", \\\"error_message\\\": \\\"Could not parse timing description: Monday morning\\\", \\\"original_timing\\\": \\\"Monday morning\\\", \\\"exception_type\\\": \\\"ValueError\\\", \\\"exception_message\\\": \\\"Could not parse time expression: Monday morning\\\"}, \\\"deadline_parsing\\\": {\\\"timezone_used\\\": \\\"UTC\\\", \\\"parsing_method\\\": \\\"fallback\\\", \\\"original_timing\\\": \\\"Monday morning\\\", \\\"parsed_timestamp\\\": null}}\"}\n",
      "{\"customer_id\": null, \"deadline_at\": null, \"timing_description\": \"By 9 AM on Monday\", \"auxiliary_pretty\": \"{\\\"parsing_error\\\": {\\\"error_type\\\": \\\"parsing_failed\\\", \\\"error_message\\\": \\\"Could not parse timing description: By 9 AM on Monday\\\", \\\"original_timing\\\": \\\"By 9 AM on Monday\\\", \\\"exception_type\\\": \\\"ValueError\\\", \\\"exception_message\\\": \\\"Could not parse time expression: By 9 AM on Monday\\\"}, \\\"deadline_parsing\\\": {\\\"timezone_used\\\": \\\"UTC\\\", \\\"parsing_method\\\": \\\"fallback\\\", \\\"original_timing\\\": \\\"By 9 AM on Monday\\\", \\\"parsed_timestamp\\\": null}}\"}\n",
      "{\"customer_id\": null, \"deadline_at\": null, \"timing_description\": \"Within 1-2 business days\", \"auxiliary_pretty\": \"{\\\"parsing_error\\\": {\\\"error_type\\\": \\\"parsing_failed\\\", \\\"error_message\\\": \\\"Could not parse timing description: Within 1-2 business days\\\", \\\"original_timing\\\": \\\"Within 1-2 business days\\\", \\\"exception_type\\\": \\\"ValueError\\\", \\\"exception_message\\\": \\\"Could not parse time expression: Within 1-2 business days\\\"}, \\\"deadline_parsing\\\": {\\\"timezone_used\\\": \\\"UTC\\\", \\\"parsing_method\\\": \\\"fallback\\\", \\\"original_timing\\\": \\\"Within 1-2 business days\\\", \\\"parsed_timestamp\\\": null}}\"}\n",
      "{\"customer_id\": null, \"deadline_at\": null, \"timing_description\": \"After the initial service appointment is completed\", \"auxiliary_pretty\": \"{\\\"parsing_error\\\": {\\\"error_type\\\": \\\"parsing_failed\\\", \\\"error_message\\\": \\\"Could not parse timing description: After the initial service appointment is completed\\\", \\\"original_timing\\\": \\\"After the initial service appointment is completed\\\", \\\"exception_type\\\": \\\"ValueError\\\", \\\"exception_message\\\": \\\"Could not parse time expression: After the initial service appointment is completed\\\"}, \\\"deadline_parsing\\\": {\\\"timezone_used\\\": \\\"UTC\\\", \\\"parsing_method\\\": \\\"fallback\\\", \\\"original_timing\\\": \\\"After the initial service appointment is completed\\\", \\\"parsed_timestamp\\\": null}}\"}\n",
      "\n",
      "The above is a JSONL file where each line is a JSON object representing a parsing error. Each error object has:\n",
      "- `timing_description`: The text that failed to parse (this is the key field for clustering)\n",
      "- `auxiliary_pretty`: JSON string containing additional error details (optional, for context)\n",
      "\n",
      "Your task:\n",
      "1. Analyze all errors and identify clusters of similar patterns\n",
      "2. Select up to 5 clusters for processing (prioritize parsable, larger clusters)\n",
      "3. Return the clustering analysis in the exact JSON format specified in the system prompt\n",
      "\n",
      "Focus on the `timing_description` field when clustering - this contains the actual time expression that needs to be parsed.\n",
      "\n",
      "Remember:\n",
      "- Cluster by semantic similarity and parsing approach, not exact string matching\n",
      "- Each error should appear in exactly one cluster\n",
      "- Select clusters that will generate the most useful parsing code\n",
      "- Use descriptive cluster_ids that will become module filenames (e.g., \"relative_dates.py\")\n",
      "\n",
      "================================================================================\n",
      "2025-12-13 17:05:51,519 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-13 17:05:51,559 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-12-13 17:05:51,597 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11130af90>\n",
      "2025-12-13 17:05:51,598 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1110e2d50> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "2025-12-13 17:05:51,647 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11129a2d0>\n",
      "2025-12-13 17:05:51,648 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-12-13 17:05:51,650 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-12-13 17:05:51,650 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-12-13 17:05:51,652 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-12-13 17:05:51,653 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running coding agent workflow...\n",
      "This will:\n",
      "  1. REASON: Cluster errors by semantic similarity\n",
      "  2. PLAN: Design code changes and test strategy\n",
      "  3. ACT: Generate parser modules and test files\n",
      "  4. VALIDATE: Run tests and verify all pass\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 17:06:22,352 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 14 Dec 2025 01:06:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=30669'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-12-13 17:06:22,354 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-13 17:06:22,355 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-12-13 17:06:22,358 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-12-13 17:06:22,363 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-12-13 17:06:22,372 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-12-13 17:06:22,377 - utils.llm_helpers - DEBUG - \n",
      "================================================================================\n",
      "[Node=Node=reason] LLM Output:\n",
      "----------------------------------------\n",
      "Response:\n",
      "```json\n",
      "{\n",
      "    \"clusters\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"error_indices\": [0, 1, 2],\n",
      "            \"commonality\": \"Relative time offsets anchored to the current date without specific clock times or weekdays\",\n",
      "            \"examples\": [\"tomorrow\", \"next week\", \"in 2 days\"],\n",
      "            \"suggested_approach\": \"Use regex to extract number and unit (days, weeks), or keyword matching for 'tomorrow', applying a timedelta to current date\",\n",
      "            \"parsability\": \"parsable\",\n",
      "            \"error_count\": 3\n",
      "        },\n",
      "        {\n",
      "            \"cluster_id\": \"weekday_time_expressions\",\n",
      "            \"error_indices\": [3, 4],\n",
      "            \"commonality\": \"Specific weekdays combined with time-of-day descriptions or specific clock times\",\n",
      "            \"examples\": [\"Monday morning\", \"By 9 AM on Monday\"],\n",
      "            \"suggested_approach\": \"Use dateutil.relativedelta to find the next occurrence of the weekday, then apply time adjustments (e.g., set hour to 9 or default 'morning' to 09:00)\",\n",
      "            \"parsability\": \"parsable\",\n",
      "            \"error_count\": 2\n",
      "        },\n",
      "        {\n",
      "            \"cluster_id\": \"business_day_ranges\",\n",
      "            \"error_indices\": [5],\n",
      "            \"commonality\": \"Time ranges specifically referencing 'business days' implying weekend exclusion\",\n",
      "            \"examples\": [\"Within 1-2 business days\"],\n",
      "            \"suggested_approach\": \"Regex to extract the numeric range, then calculate target date by adding days while skipping Saturdays and Sundays\",\n",
      "            \"parsability\": \"parsable\",\n",
      "            \"error_count\": 1\n",
      "        },\n",
      "        {\n",
      "            \"cluster_id\": \"event_triggers\",\n",
      "            \"error_indices\": [6],\n",
      "            \"commonality\": \"Timing dependent on the completion of a specific external event rather than a calendar date\",\n",
      "            \"examples\": [\"After the initial service appointment is completed\"],\n",
      "            \"suggested_approach\": \"Requires external state/context. Tag as unparseable-date but parsable-trigger\",\n",
      "            \"parsability\": \"context_dependent\",\n",
      "            \"error_count\": 1\n",
      "        }\n",
      "    ],\n",
      "    \"selected_clusters\": [\"relative_date_offsets\", \"weekday_time_expressions\", \"business_day_ranges\"],\n",
      "    \"total_errors_analyzed\": 7,\n",
      "    \"total_clusters_identified\": 4,\n",
      "    \"clusters_selected_count\": 3\n",
      "}\n",
      "```\n",
      "================================================================================\n",
      "2025-12-13 17:06:22,378 - utils.llm_json_parser - DEBUG - [Node] Original response content length: 2296 chars\n",
      "2025-12-13 17:06:22,379 - utils.llm_json_parser - DEBUG - [Node] Original response preview (first 250 + last 250): ```json\n",
      "{\n",
      "    \"clusters\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"error_indices\": [0, 1, 2],\n",
      "            \"commonality\": \"Relative time offsets anchored to the current date without specific clock times or weekdays\",... [truncated 1796 chars] ...       \"error_count\": 1\n",
      "        }\n",
      "    ],\n",
      "    \"selected_clusters\": [\"relative_date_offsets\", \"weekday_time_expressions\", \"business_day_ranges\"],\n",
      "    \"total_errors_analyzed\": 7,\n",
      "    \"total_clusters_identified\": 4,\n",
      "    \"clusters_selected_count\": 3\n",
      "}\n",
      "```\n",
      "2025-12-13 17:06:22,381 - utils.llm_json_parser - DEBUG - [Node] After cleaning (removed markdown/prefixes): length=2284 chars\n",
      "2025-12-13 17:06:22,382 - utils.llm_json_parser - DEBUG - [Node] Cleaned content preview (first 250 + last 250): {\n",
      "    \"clusters\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"error_indices\": [0, 1, 2],\n",
      "            \"commonality\": \"Relative time offsets anchored to the current date without specific clock times or weekdays\",\n",
      "       ... [truncated 1784 chars] ...           \"error_count\": 1\n",
      "        }\n",
      "    ],\n",
      "    \"selected_clusters\": [\"relative_date_offsets\", \"weekday_time_expressions\", \"business_day_ranges\"],\n",
      "    \"total_errors_analyzed\": 7,\n",
      "    \"total_clusters_identified\": 4,\n",
      "    \"clusters_selected_count\": 3\n",
      "}\n",
      "2025-12-13 17:06:22,382 - utils.llm_json_parser - DEBUG - [Node] After repair: length=2284 chars, is_valid_json=True\n",
      "2025-12-13 17:06:22,384 - utils.llm_json_parser - DEBUG - [Node] Repaired content preview (first 250 + last 250): {\n",
      "    \"clusters\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"error_indices\": [0, 1, 2],\n",
      "            \"commonality\": \"Relative time offsets anchored to the current date without specific clock times or weekdays\",\n",
      "       ... [truncated 1784 chars] ...           \"error_count\": 1\n",
      "        }\n",
      "    ],\n",
      "    \"selected_clusters\": [\"relative_date_offsets\", \"weekday_time_expressions\", \"business_day_ranges\"],\n",
      "    \"total_errors_analyzed\": 7,\n",
      "    \"total_clusters_identified\": 4,\n",
      "    \"clusters_selected_count\": 3\n",
      "}\n",
      "2025-12-13 17:06:22,384 - utils.llm_json_parser - DEBUG - [Node] Attempting full JSON block parse (text length: 2284 chars)\n",
      "2025-12-13 17:06:22,385 - utils.llm_json_parser - DEBUG - [Node] Full JSON block parse succeeded, type: dict\n",
      "2025-12-13 17:06:22,385 - utils.llm_json_parser - DEBUG - [Node] Normalizing dict output: single dict\n",
      "2025-12-13 17:06:22,386 - utils.llm_helpers - DEBUG - \n",
      "================================================================================\n",
      "[Node=Node=plan] LLM Input:\n",
      "----------------------------------------\n",
      "System Prompt:\n",
      "\n",
      "You are an expert Python developer specializing in natural language time parsing and test-driven development.\n",
      "\n",
      "Your task is to design a plan for implementing parsing modules that will handle specific error clusters identified from parsing failures.\n",
      "\n",
      "## Context\n",
      "\n",
      "We are building a modular time parser system where:\n",
      "- Each error cluster gets its own Python module in `time_parser/parsers/`\n",
      "- Each module exports a `parse(text: str) -> datetime | None` function\n",
      "- The main parser orchestrates by trying each cluster module in sequence\n",
      "- Each cluster module also gets a corresponding test file in `time_parser/tests/`\n",
      "\n",
      "## Module Structure Requirements\n",
      "\n",
      "Each cluster module must:\n",
      "1. **Export a `parse()` function** with signature: `def parse(text: str) -> datetime | None`\n",
      "2. **Return `datetime` objects** with UTC timezone (use `datetime.now(UTC)` or `datetime(..., tzinfo=UTC)`)\n",
      "3. **Return `None`** if the input doesn't match this cluster's patterns (not an error - other clusters will try)\n",
      "4. **Use standard libraries**: `datetime`, `re`, `dateutil.relativedelta` (if needed)\n",
      "5. **Handle edge cases**: Case-insensitive matching, whitespace, punctuation variations\n",
      "\n",
      "## Test Structure Requirements\n",
      "\n",
      "Each test file must:\n",
      "1. **Use pytest** with `@pytest.mark.parametrize` for multiple test cases\n",
      "2. **Test all error cases** from the cluster (use the examples from REASON node)\n",
      "3. **Assert valid datetime**: Result is not None, is datetime instance, has UTC timezone\n",
      "4. **Follow naming**: `test_<cluster_id>.py` matches `parsers/<cluster_id>.py`\n",
      "\n",
      "## Planning Process\n",
      "\n",
      "For each selected cluster, you must plan:\n",
      "\n",
      "1. **Parsing Strategy**:\n",
      "   - What regex patterns or dateutil features will be used?\n",
      "   - How will you handle variations (case, whitespace, punctuation)?\n",
      "   - What edge cases need special handling?\n",
      "\n",
      "2. **Code Structure**:\n",
      "   - What helper functions (if any) will the module need?\n",
      "   - How will patterns be organized (regex dict, if/elif chain, etc.)?\n",
      "   - What imports are needed?\n",
      "\n",
      "3. **Test Cases**:\n",
      "   - List all error examples from the cluster that will become test cases\n",
      "   - What additional edge cases should be tested?\n",
      "   - What should the expected datetime values be (relative to \"now\")?\n",
      "\n",
      "4. **Dependencies**:\n",
      "   - What Python standard library modules are needed?\n",
      "   - Are any third-party packages required (dateutil, etc.)?\n",
      "\n",
      "## Output Requirements\n",
      "\n",
      "You must output a JSON object with the following structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"cluster_plans\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_dates\",\n",
      "            \"parsing_strategy\": \"Use dateutil.relativedelta for relative date arithmetic. Match patterns like 'tomorrow', 'next week', 'in N days', 'Monday morning' using regex, then calculate datetime relative to now(UTC).\",\n",
      "            \"code_structure\": \"Single parse() function with regex pattern matching dictionary. Patterns map to lambda functions that calculate relative dates.\",\n",
      "            \"test_cases\": [\n",
      "                {\"input\": \"tomorrow\", \"description\": \"Basic relative date\"},\n",
      "                {\"input\": \"next week\", \"description\": \"Week-based relative date\"},\n",
      "                {\"input\": \"in 2 days\", \"description\": \"N days in future\"},\n",
      "                {\"input\": \"Monday morning\", \"description\": \"Day of week with time of day\"}\n",
      "            ],\n",
      "            \"dependencies\": [\"datetime\", \"re\", \"dateutil.relativedelta\"],\n",
      "            \"edge_cases\": [\"Case variations (Tomorrow, TOMORROW)\", \"Whitespace variations\", \"Punctuation (tomorrow!)\"]\n",
      "        }\n",
      "    ],\n",
      "    \"implementation_notes\": \"All modules will be generated together. Ensure consistent error handling and return types across modules.\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Field Descriptions:**\n",
      "- `cluster_plans`: Array of plans, one per selected cluster\n",
      "  - `cluster_id`: Must match cluster_id from REASON node\n",
      "  - `parsing_strategy`: High-level description of how to parse this cluster\n",
      "  - `code_structure`: Description of code organization (functions, data structures, etc.)\n",
      "  - `test_cases`: List of test case objects with input and description\n",
      "  - `dependencies`: List of required imports\n",
      "  - `edge_cases`: List of edge cases to handle\n",
      "- `implementation_notes`: Any cross-cluster considerations\n",
      "\n",
      "## Important Guidelines\n",
      "\n",
      "- **Keep modules focused**: Each module handles one cluster's patterns\n",
      "- **Use standard libraries**: Prefer datetime, re, dateutil over custom solutions\n",
      "- **Handle variations**: Case-insensitive, whitespace-tolerant, punctuation-tolerant\n",
      "- **Return None for non-matches**: Don't raise exceptions - let other clusters try\n",
      "- **UTC timezone**: All datetimes must be timezone-aware with UTC\n",
      "- **Test comprehensively**: Include all error examples plus edge cases\n",
      "\n",
      "----------------------------------------\n",
      "User Prompt:\n",
      "\n",
      "Selected Error Clusters for Processing:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"cluster_id\": \"relative_date_offsets\",\n",
      "    \"error_indices\": [\n",
      "      0,\n",
      "      1,\n",
      "      2\n",
      "    ],\n",
      "    \"commonality\": \"Relative time offsets anchored to the current date without specific clock times or weekdays\",\n",
      "    \"examples\": [\n",
      "      \"tomorrow\",\n",
      "      \"next week\",\n",
      "      \"in 2 days\"\n",
      "    ],\n",
      "    \"suggested_approach\": \"Use regex to extract number and unit (days, weeks), or keyword matching for 'tomorrow', applying a timedelta to current date\",\n",
      "    \"parsability\": \"parsable\",\n",
      "    \"error_count\": 3\n",
      "  },\n",
      "  {\n",
      "    \"cluster_id\": \"weekday_time_expressions\",\n",
      "    \"error_indices\": [\n",
      "      3,\n",
      "      4\n",
      "    ],\n",
      "    \"commonality\": \"Specific weekdays combined with time-of-day descriptions or specific clock times\",\n",
      "    \"examples\": [\n",
      "      \"Monday morning\",\n",
      "      \"By 9 AM on Monday\"\n",
      "    ],\n",
      "    \"suggested_approach\": \"Use dateutil.relativedelta to find the next occurrence of the weekday, then apply time adjustments (e.g., set hour to 9 or default 'morning' to 09:00)\",\n",
      "    \"parsability\": \"parsable\",\n",
      "    \"error_count\": 2\n",
      "  },\n",
      "  {\n",
      "    \"cluster_id\": \"business_day_ranges\",\n",
      "    \"error_indices\": [\n",
      "      5\n",
      "    ],\n",
      "    \"commonality\": \"Time ranges specifically referencing 'business days' implying weekend exclusion\",\n",
      "    \"examples\": [\n",
      "      \"Within 1-2 business days\"\n",
      "    ],\n",
      "    \"suggested_approach\": \"Regex to extract the numeric range, then calculate target date by adding days while skipping Saturdays and Sundays\",\n",
      "    \"parsability\": \"parsable\",\n",
      "    \"error_count\": 1\n",
      "  }\n",
      "]\n",
      "\n",
      "Existing Cluster Modules (if any):\n",
      "\n",
      "[]\n",
      "\n",
      "The cluster_analysis contains the selected clusters from the REASON node, including:\n",
      "- cluster_id: The identifier that will become the module filename\n",
      "- examples: Example timing_description strings that failed to parse\n",
      "- suggested_approach: High-level parsing approach\n",
      "- error_indices: Original error indices (for reference)\n",
      "\n",
      "The existing_cluster_modules list shows any cluster modules that already exist (so you can see what patterns are already handled).\n",
      "\n",
      "Your task:\n",
      "1. For each selected cluster, design a detailed plan for the parsing module\n",
      "2. Plan the corresponding test file with all test cases\n",
      "3. Consider how to handle edge cases and variations\n",
      "4. Return the planning document in the exact JSON format specified in the system prompt\n",
      "\n",
      "Focus on:\n",
      "- Creating efficient, maintainable code\n",
      "- Handling all examples from the cluster\n",
      "- Using standard Python libraries where possible\n",
      "- Writing comprehensive tests\n",
      "- Ensuring modules can coexist (no conflicts)\n",
      "\n",
      "================================================================================\n",
      "2025-12-13 17:06:22,390 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-13 17:06:22,392 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-12-13 17:06:22,392 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-12-13 17:06:22,393 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-12-13 17:06:22,393 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-12-13 17:06:22,393 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-12-13 17:06:50,486 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 14 Dec 2025 01:06:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=27962'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-12-13 17:06:50,487 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-12-13 17:06:50,488 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-12-13 17:06:50,490 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-12-13 17:06:50,490 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-12-13 17:06:50,491 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-12-13 17:06:50,494 - utils.llm_helpers - DEBUG - \n",
      "================================================================================\n",
      "[Node=Node=plan] LLM Output:\n",
      "----------------------------------------\n",
      "Response:\n",
      "```json\n",
      "{\n",
      "    \"cluster_plans\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"parsing_strategy\": \"Use regex patterns to identify three primary structures: 1) Static keywords ('tomorrow'), 2) 'Next' relative units ('next week', 'next month'), and 3) Numeric offsets ('in 2 days', 'in 5 weeks'). Map captured units to `dateutil.relativedelta` arguments. Calculate the resulting datetime based on `datetime.now(timezone.utc)`.\",\n",
      "            \"code_structure\": \"Single `parse(text)` function. Define a dictionary mapping time units (day, week, month) to `relativedelta` keywords. Use a series of regex checks: if 'tomorrow' matches, return now + 1 day; if 'next <unit>' matches, return now + 1 unit; if 'in <num> <unit>' matches, return now + num units. Return None if no patterns match.\",\n",
      "            \"test_cases\": [\n",
      "                {\"input\": \"tomorrow\", \"description\": \"Static keyword 'tomorrow'\"},\n",
      "                {\"input\": \"next week\", \"description\": \"'Next' keyword with unit\"},\n",
      "                {\"input\": \"in 2 days\", \"description\": \"Numeric offset 'in N days'\"},\n",
      "                {\"input\": \"in 1 week\", \"description\": \"Numeric offset with singular unit\"},\n",
      "                {\"input\": \"in 5 months\", \"description\": \"Larger unit offset\"}\n",
      "            ],\n",
      "            \"dependencies\": [\"re\", \"datetime\", \"dateutil.relativedelta\"],\n",
      "            \"edge_cases\": [\n",
      "                \"Case sensitivity (Tomorrow, Next Week)\",\n",
      "                \"Extra whitespace (in  2 days)\",\n",
      "                \"Unit pluralization (day vs days)\",\n",
      "                \"Punctuation (tomorrow!)\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"cluster_id\": \"weekday_time_expressions\",\n",
      "            \"parsing_strategy\": \"This module detects a specific day of the week combined with a time expression. 1. Detect the weekday (Monday-Sunday) to calculate the date using `relativedelta(weekday=XX)`. 2. Detect the time component, either specific ('9 AM', '14:00') or vague ('morning', 'afternoon'). 3. Combine date and time. If time is 'morning', default to 09:00; 'afternoon' to 14:00.\",\n",
      "            \"code_structure\": \"Define mappings for weekdays (MONDAY -> relativedelta.MO) and vague times (morning -> 9, afternoon -> 14). `parse(text)` first looks for a weekday name. If found, it looks for time patterns within the string. Use `datetime.now(timezone.utc)` as anchor, apply weekday offset, then replace hour/minute.\",\n",
      "            \"test_cases\": [\n",
      "                {\"input\": \"Monday morning\", \"description\": \"Weekday with vague time 'morning'\"},\n",
      "                {\"input\": \"By 9 AM on Monday\", \"description\": \"Specific time with preposition 'on'\"},\n",
      "                {\"input\": \"Tuesday afternoon\", \"description\": \"Weekday with vague time 'afternoon'\"},\n",
      "                {\"input\": \"Friday at 5pm\", \"description\": \"Weekday with compact time format\"}\n",
      "            ],\n",
      "            \"dependencies\": [\"re\", \"datetime\", \"dateutil.relativedelta\"],\n",
      "            \"edge_cases\": [\n",
      "                \"Case insensitivity (monday Morning)\",\n",
      "                \"Mixed order (9am Monday vs Monday 9am)\",\n",
      "                \"Time formats (9am, 9:00 AM, 9 AM)\",\n",
      "                \"Handling 'on' preposition optionally\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"cluster_id\": \"business_day_ranges\",\n",
      "            \"parsing_strategy\": \"Extract numeric values associated with 'business days' or 'working days'. If a range is provided ('1-2 days'), take the upper bound (2) to represent the completion deadline. Iterate from the current date adding 1 day at a time, checking `weekday()` to skip Saturday (5) and Sunday (6) until the target count is reached.\",\n",
      "            \"code_structure\": \"`parse(text)` uses regex to find `(?:within|in)\\\\s+(\\\\d+)(?:-(\\\\d+))?\\\\s+business\\\\s+days?`. Extract the count (use group 2 if present, else group 1). Implement a helper loop/generator that yields valid business dates starting from now(utc) to calculate the final timestamp.\",\n",
      "            \"test_cases\": [\n",
      "                {\"input\": \"Within 1-2 business days\", \"description\": \"Range of business days, taking max\"},\n",
      "                {\"input\": \"in 3 business days\", \"description\": \"Exact number of business days\"},\n",
      "                {\"input\": \"5 working days\", \"description\": \"Alternative terminology 'working days'\"}\n",
      "            ],\n",
      "            \"dependencies\": [\"re\", \"datetime\"],\n",
      "            \"edge_cases\": [\n",
      "                \"Ranges (1-2) vs single numbers (2)\",\n",
      "                \"Terminology (business days vs working days)\",\n",
      "                \"Weekend boundaries (calculating across a weekend)\",\n",
      "                \"Singular/Plural (1 business day)\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"implementation_notes\": \"All modules must prioritize UTC timezone correctness using `datetime.now(timezone.utc)`. String matching should always be case-insensitive using `re.IGNORECASE`. Return `None` immediately if the primary pattern (e.g., the specific keyword or weekday name) is missing to keep the main parser efficient.\"\n",
      "}\n",
      "```\n",
      "================================================================================\n",
      "2025-12-13 17:06:50,494 - utils.llm_json_parser - DEBUG - [Node] Original response content length: 4939 chars\n",
      "2025-12-13 17:06:50,495 - utils.llm_json_parser - DEBUG - [Node] Original response preview (first 250 + last 250): ```json\n",
      "{\n",
      "    \"cluster_plans\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"parsing_strategy\": \"Use regex patterns to identify three primary structures: 1) Static keywords ('tomorrow'), 2) 'Next' relative units ('next w... [truncated 4439 chars] ... `datetime.now(timezone.utc)`. String matching should always be case-insensitive using `re.IGNORECASE`. Return `None` immediately if the primary pattern (e.g., the specific keyword or weekday name) is missing to keep the main parser efficient.\"\n",
      "}\n",
      "```\n",
      "2025-12-13 17:06:50,496 - utils.llm_json_parser - DEBUG - [Node] After cleaning (removed markdown/prefixes): length=4927 chars\n",
      "2025-12-13 17:06:50,496 - utils.llm_json_parser - DEBUG - [Node] Cleaned content preview (first 250 + last 250): {\n",
      "    \"cluster_plans\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"parsing_strategy\": \"Use regex patterns to identify three primary structures: 1) Static keywords ('tomorrow'), 2) 'Next' relative units ('next week', 'n... [truncated 4427 chars] ...sing `datetime.now(timezone.utc)`. String matching should always be case-insensitive using `re.IGNORECASE`. Return `None` immediately if the primary pattern (e.g., the specific keyword or weekday name) is missing to keep the main parser efficient.\"\n",
      "}\n",
      "2025-12-13 17:06:50,497 - utils.llm_json_parser - DEBUG - [Node] After repair: length=4927 chars, is_valid_json=True\n",
      "2025-12-13 17:06:50,498 - utils.llm_json_parser - DEBUG - [Node] Repaired content preview (first 250 + last 250): {\n",
      "    \"cluster_plans\": [\n",
      "        {\n",
      "            \"cluster_id\": \"relative_date_offsets\",\n",
      "            \"parsing_strategy\": \"Use regex patterns to identify three primary structures: 1) Static keywords ('tomorrow'), 2) 'Next' relative units ('next week', 'n... [truncated 4427 chars] ...sing `datetime.now(timezone.utc)`. String matching should always be case-insensitive using `re.IGNORECASE`. Return `None` immediately if the primary pattern (e.g., the specific keyword or weekday name) is missing to keep the main parser efficient.\"\n",
      "}\n",
      "2025-12-13 17:06:50,499 - utils.llm_json_parser - DEBUG - [Node] Attempting full JSON block parse (text length: 4927 chars)\n",
      "2025-12-13 17:06:50,500 - utils.llm_json_parser - DEBUG - [Node] Full JSON block parse succeeded, type: dict\n",
      "2025-12-13 17:06:50,500 - utils.llm_json_parser - DEBUG - [Node] Normalizing dict output: single dict\n",
      "2025-12-13 17:06:50,503 - utils.llm_helpers - DEBUG - \n",
      "================================================================================\n",
      "[Node=Node=act] LLM Input:\n",
      "----------------------------------------\n",
      "System Prompt:\n",
      "\n",
      "You are an expert Python developer specializing in natural language time parsing. Your task is to generate complete, production-ready Python modules and test files based on the planning document.\n",
      "\n",
      "## Context\n",
      "\n",
      "You are generating code for a modular time parser system where:\n",
      "- Each error cluster gets its own module: `time_parser/parsers/<cluster_id>.py`\n",
      "- Each module exports: `def parse(text: str) -> datetime | None`\n",
      "- Each cluster gets a test file: `time_parser/tests/test_<cluster_id>.py`\n",
      "- Modules are discovered and loaded dynamically by the main parser\n",
      "\n",
      "## Code Generation Requirements\n",
      "\n",
      "### Module Code (`parsers/<cluster_id>.py`)\n",
      "\n",
      "**Required Structure:**\n",
      "```python\n",
      "\"\"\"Parser module for <cluster_id> cluster.\"\"\"\n",
      "from datetime import datetime, timedelta, UTC\n",
      "import re\n",
      "# Additional imports as needed (e.g., from dateutil.relativedelta import relativedelta)\n",
      "\n",
      "def parse(text: str) -> datetime | None:\n",
      "    \"\"\"Parse <cluster_description> expressions.\n",
      "    \n",
      "    Args:\n",
      "        text: Time expression string to parse\n",
      "        \n",
      "    Returns:\n",
      "        datetime object with UTC timezone if successful, None otherwise\n",
      "    \"\"\"\n",
      "    # Implementation here\n",
      "    # Must return datetime with UTC timezone or None\n",
      "```\n",
      "\n",
      "**Critical Requirements:**\n",
      "1. **Function signature**: Must be exactly `def parse(text: str) -> datetime | None`\n",
      "2. **Return type**: Return `datetime` with UTC timezone or `None` (never raise exceptions for non-matches)\n",
      "3. **Case-insensitive**: Handle \"Tomorrow\", \"tomorrow\", \"TOMORROW\" the same way\n",
      "4. **Whitespace-tolerant**: Handle extra spaces, tabs, newlines\n",
      "5. **Punctuation-tolerant**: Handle trailing punctuation (e.g., \"tomorrow!\", \"next week.\")\n",
      "6. **UTC timezone**: All datetimes must use `UTC` timezone\n",
      "7. **Code quality**: Use clear variable names, add comments for complex logic\n",
      "8. **Efficiency**: Use regex efficiently, avoid unnecessary loops\n",
      "\n",
      "### Test File Code (`tests/test_<cluster_id>.py`)\n",
      "\n",
      "**Required Structure:**\n",
      "```python\n",
      "\"\"\"Tests for <cluster_id> parser module.\"\"\"\n",
      "import pytest\n",
      "from datetime import datetime, UTC\n",
      "from time_parser.parsers.<cluster_id> import parse\n",
      "\n",
      "@pytest.mark.parametrize(\"input_text,expected_day_offset\", [\n",
      "    (\"tomorrow\", 1),\n",
      "    (\"next week\", 7),\n",
      "    # ... more test cases\n",
      "])\n",
      "def test_<cluster_id>(input_text: str, expected_day_offset: int):\n",
      "    \"\"\"Test parsing of <cluster_description> expressions.\"\"\"\n",
      "    result = parse(input_text)\n",
      "    assert result is not None, f\"Failed to parse: {input_text}\"\n",
      "    assert isinstance(result, datetime), f\"Result not datetime: {input_text}\"\n",
      "    assert result.tzinfo is not None, f\"Result not timezone-aware: {input_text}\"\n",
      "    assert result.tzinfo == UTC, f\"Result not UTC: {input_text}\"\n",
      "    # Additional assertions as needed\n",
      "```\n",
      "\n",
      "**Critical Requirements:**\n",
      "1. **Parameterized tests**: Use `@pytest.mark.parametrize` for multiple cases\n",
      "2. **Test all examples**: Include all error examples from the cluster\n",
      "3. **Assertions**: Check for None, datetime type, timezone awareness, UTC timezone\n",
      "4. **Test edge cases**: Case variations, whitespace, punctuation\n",
      "5. **Clear test names**: Descriptive test function names\n",
      "\n",
      "## Output Requirements\n",
      "\n",
      "You must output a JSON object with the following structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"cluster_modules\": {\n",
      "        \"relative_dates\": \"# time_parser/parsers/relative_dates.py\n",
      "\"\"\"Parser module for relative date expressions.\"\"\"\n",
      "from datetime import datetime, timedelta, UTC\n",
      "import re\n",
      "\n",
      "def parse(text: str) -> datetime | None:\n",
      "    # ... complete module code ...\",\n",
      "        \"specific_dates\": \"# time_parser/parsers/specific_dates.py\n",
      "\"\"\"Parser module for specific date expressions.\"\"\"\n",
      "# ... complete module code ...\"\n",
      "    },\n",
      "    \"test_files\": {\n",
      "        \"relative_dates\": \"# time_parser/tests/test_relative_dates.py\n",
      "\"\"\"Tests for relative_dates parser module.\"\"\"\n",
      "import pytest\n",
      "# ... complete test file code ...\",\n",
      "        \"specific_dates\": \"# time_parser/tests/test_specific_dates.py\n",
      "\"\"\"Tests for specific_dates parser module.\"\"\"\n",
      "# ... complete test file code ...\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "**Field Descriptions:**\n",
      "- `cluster_modules`: Dictionary mapping cluster_id to complete module code (as string)\n",
      "  - Code must be complete, syntactically correct Python\n",
      "  - Include file header comment with module description\n",
      "  - Code should be ready to write directly to file\n",
      "- `test_files`: Dictionary mapping cluster_id to complete test file code (as string)\n",
      "  - Code must be complete, syntactically correct Python\n",
      "  - Include file header comment\n",
      "  - All test cases from planning document must be included\n",
      "\n",
      "## Code Quality Guidelines\n",
      "\n",
      "1. **Follow PEP 8**: Use proper Python style\n",
      "2. **Add docstrings**: Document functions and modules\n",
      "3. **Handle edge cases**: Case, whitespace, punctuation variations\n",
      "4. **Use type hints**: Include return type annotations\n",
      "5. **Error handling**: Return None for non-matches (don't raise exceptions)\n",
      "6. **Efficient patterns**: Use compiled regex if repeated, use dict lookups for patterns\n",
      "7. **Comments**: Add comments for complex logic or non-obvious decisions\n",
      "\n",
      "## Important Notes\n",
      "\n",
      "- Generate COMPLETE files - not snippets or partial code\n",
      "- Each module must be self-contained and importable\n",
      "- Test files must import from the corresponding parser module\n",
      "- All code must be syntactically correct and ready to execute\n",
      "- Use UTC timezone for all datetime objects\n",
      "- Return None (not raise exceptions) when input doesn't match cluster patterns\n",
      "\n",
      "----------------------------------------\n",
      "User Prompt:\n",
      "\n",
      "Code Planning Document:\n",
      "\n",
      "{\n",
      "  \"cluster_plans\": [\n",
      "    {\n",
      "      \"cluster_id\": \"relative_date_offsets\",\n",
      "      \"parsing_strategy\": \"Use regex patterns to identify three primary structures: 1) Static keywords ('tomorrow'), 2) 'Next' relative units ('next week', 'next month'), and 3) Numeric offsets ('in 2 days', 'in 5 weeks'). Map captured units to `dateutil.relativedelta` arguments. Calculate the resulting datetime based on `datetime.now(timezone.utc)`.\",\n",
      "      \"code_structure\": \"Single `parse(text)` function. Define a dictionary mapping time units (day, week, month) to `relativedelta` keywords. Use a series of regex checks: if 'tomorrow' matches, return now + 1 day; if 'next <unit>' matches, return now + 1 unit; if 'in <num> <unit>' matches, return now + num units. Return None if no patterns match.\",\n",
      "      \"test_cases\": [\n",
      "        {\n",
      "          \"input\": \"tomorrow\",\n",
      "          \"description\": \"Static keyword 'tomorrow'\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"next week\",\n",
      "          \"description\": \"'Next' keyword with unit\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"in 2 days\",\n",
      "          \"description\": \"Numeric offset 'in N days'\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"in 1 week\",\n",
      "          \"description\": \"Numeric offset with singular unit\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"in 5 months\",\n",
      "          \"description\": \"Larger unit offset\"\n",
      "        }\n",
      "      ],\n",
      "      \"dependencies\": [\n",
      "        \"re\",\n",
      "        \"datetime\",\n",
      "        \"dateutil.relativedelta\"\n",
      "      ],\n",
      "      \"edge_cases\": [\n",
      "        \"Case sensitivity (Tomorrow, Next Week)\",\n",
      "        \"Extra whitespace (in  2 days)\",\n",
      "        \"Unit pluralization (day vs days)\",\n",
      "        \"Punctuation (tomorrow!)\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"cluster_id\": \"weekday_time_expressions\",\n",
      "      \"parsing_strategy\": \"This module detects a specific day of the week combined with a time expression. 1. Detect the weekday (Monday-Sunday) to calculate the date using `relativedelta(weekday=XX)`. 2. Detect the time component, either specific ('9 AM', '14:00') or vague ('morning', 'afternoon'). 3. Combine date and time. If time is 'morning', default to 09:00; 'afternoon' to 14:00.\",\n",
      "      \"code_structure\": \"Define mappings for weekdays (MONDAY -> relativedelta.MO) and vague times (morning -> 9, afternoon -> 14). `parse(text)` first looks for a weekday name. If found, it looks for time patterns within the string. Use `datetime.now(timezone.utc)` as anchor, apply weekday offset, then replace hour/minute.\",\n",
      "      \"test_cases\": [\n",
      "        {\n",
      "          \"input\": \"Monday morning\",\n",
      "          \"description\": \"Weekday with vague time 'morning'\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"By 9 AM on Monday\",\n",
      "          \"description\": \"Specific time with preposition 'on'\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"Tuesday afternoon\",\n",
      "          \"description\": \"Weekday with vague time 'afternoon'\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"Friday at 5pm\",\n",
      "          \"description\": \"Weekday with compact time format\"\n",
      "        }\n",
      "      ],\n",
      "      \"dependencies\": [\n",
      "        \"re\",\n",
      "        \"datetime\",\n",
      "        \"dateutil.relativedelta\"\n",
      "      ],\n",
      "      \"edge_cases\": [\n",
      "        \"Case insensitivity (monday Morning)\",\n",
      "        \"Mixed order (9am Monday vs Monday 9am)\",\n",
      "        \"Time formats (9am, 9:00 AM, 9 AM)\",\n",
      "        \"Handling 'on' preposition optionally\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"cluster_id\": \"business_day_ranges\",\n",
      "      \"parsing_strategy\": \"Extract numeric values associated with 'business days' or 'working days'. If a range is provided ('1-2 days'), take the upper bound (2) to represent the completion deadline. Iterate from the current date adding 1 day at a time, checking `weekday()` to skip Saturday (5) and Sunday (6) until the target count is reached.\",\n",
      "      \"code_structure\": \"`parse(text)` uses regex to find `(?:within|in)\\\\s+(\\\\d+)(?:-(\\\\d+))?\\\\s+business\\\\s+days?`. Extract the count (use group 2 if present, else group 1). Implement a helper loop/generator that yields valid business dates starting from now(utc) to calculate the final timestamp.\",\n",
      "      \"test_cases\": [\n",
      "        {\n",
      "          \"input\": \"Within 1-2 business days\",\n",
      "          \"description\": \"Range of business days, taking max\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"in 3 business days\",\n",
      "          \"description\": \"Exact number of business days\"\n",
      "        },\n",
      "        {\n",
      "          \"input\": \"5 working days\",\n",
      "          \"description\": \"Alternative terminology 'working days'\"\n",
      "        }\n",
      "      ],\n",
      "      \"dependencies\": [\n",
      "        \"re\",\n",
      "        \"datetime\"\n",
      "      ],\n",
      "      \"edge_cases\": [\n",
      "        \"Ranges (1-2) vs single numbers (2)\",\n",
      "        \"Terminology (business days vs working days)\",\n",
      "        \"Weekend boundaries (calculating across a weekend)\",\n",
      "        \"Singular/Plural (1 business day)\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "The code_plan contains the detailed plans for each selected cluster, including:\n",
      "- parsing_strategy: How to parse this cluster\n",
      "- code_structure: Code organization approach\n",
      "- test_cases: All test cases to include\n",
      "- dependencies: Required imports\n",
      "- edge_cases: Edge cases to handle\n",
      "\n",
      "Your task:\n",
      "1. Generate complete Python module code for each cluster in `cluster_modules`\n",
      "2. Generate complete test file code for each cluster in `test_files`\n",
      "3. Ensure all code is syntactically correct and follows the requirements\n",
      "4. Include all test cases from the planning document\n",
      "5. Return the code in the exact JSON format specified in the system prompt\n",
      "\n",
      "Remember:\n",
      "- Each module must export a `parse(text: str) -> datetime | None` function\n",
      "- All datetimes must use UTC timezone\n",
      "- Return None (not raise exceptions) for non-matches\n",
      "- Test files must use pytest with parameterized tests\n",
      "- Code must be complete and ready to write to files\n",
      "\n",
      "================================================================================\n",
      "2025-12-13 17:06:50,505 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-12-13 17:06:50,508 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-12-13 17:06:50,509 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-12-13 17:06:50,510 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-12-13 17:06:50,511 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-12-13 17:06:50,512 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    }
   ],
   "source": [
    "# Run agent workflow\n",
    "print(\"Running coding agent workflow...\")\n",
    "print(\"This will:\")\n",
    "print(\"  1. REASON: Cluster errors by semantic similarity\")\n",
    "print(\"  2. PLAN: Design code changes and test strategy\")\n",
    "print(\"  3. ACT: Generate parser modules and test files\")\n",
    "print(\"  4. VALIDATE: Run tests and verify all pass\")\n",
    "print()\n",
    "\n",
    "result = workflow.run(initial_state=initial_state)\n",
    "\n",
    "print(\"\\n✓ Workflow completed!\")\n",
    "print(f\"Result keys: {list(result.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display agent results\n",
    "print(\"Agent Results:\")\n",
    "print(f\"  Success: {result.get('success', False)}\")\n",
    "print(f\"  Processed clusters: {result.get('processed_clusters', [])}\")\n",
    "print(f\"  Errors removed: {result.get('errors_removed_count', 0)}\")\n",
    "print(f\"  Parser updated: {result.get('parser_updated', False)}\")\n",
    "print(f\"  Tests passed: {result.get('tests_passed', False)}\")\n",
    "print(f\"  Retry count: {result.get('retry_count', 0)}\")\n",
    "print(f\"  Generated modules: {list(result.get('generated_cluster_modules', {}).keys())}\")\n",
    "print(f\"  Generated test files: {list(result.get('generated_test_files', {}).keys())}\")\n",
    "\n",
    "if result.get('message'):\n",
    "    print(f\"  Message: {result['message']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Verification\n",
    "\n",
    "Let's verify that the parser now works with previously failing inputs and check the test results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload parser after agent update\n",
    "parser = reload_parser(\"time_parser/parsers\")\n",
    "print(\"✓ Parser reloaded with updated cluster modules\")\n",
    "\n",
    "# Show updated parsers directory\n",
    "parsers_dir = Path(\"time_parser/parsers\")\n",
    "if parsers_dir.exists():\n",
    "    parser_files = list(parsers_dir.glob(\"*.py\"))\n",
    "    print(f\"Parser modules: {[f.name for f in parser_files if f.name != '__init__.py']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parser with previously failing inputs\n",
    "previously_failing = [\n",
    "    \"tomorrow\",\n",
    "    \"next week\",\n",
    "    \"in 2 days\",\n",
    "    \"Monday morning\",\n",
    "]\n",
    "\n",
    "print(\"Testing parser with previously failing inputs:\")\n",
    "for input_text in previously_failing:\n",
    "    try:\n",
    "        result = parser.parse(input_text)\n",
    "        print(f\"✓ Parsed '{input_text}': {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Still failed to parse '{input_text}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pytest and display results\n",
    "test_results = run_pytest(\"time_parser/tests\", verbose=True)\n",
    "\n",
    "print(f\"All tests passed: {test_results['all_passed']}\")\n",
    "print(f\"Return code: {test_results['returncode']}\")\n",
    "print(f\"\\nTest output:\\n{test_results['test_output']}\")\n",
    "\n",
    "if test_results['test_errors']:\n",
    "    print(f\"\\nTest errors:\\n{test_results['test_errors']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show updated error queue (should have fewer errors)\n",
    "remaining_errors = read_error_queue(error_queue_path)\n",
    "print(f\"Remaining errors in queue: {len(remaining_errors)}\")\n",
    "print(f\"Errors removed: {result.get('errors_removed_count', 0)}\")\n",
    "\n",
    "if remaining_errors:\n",
    "    print(\"\\nRemaining errors (not yet processed):\")\n",
    "    for i, error in enumerate(remaining_errors[:5]):\n",
    "        print(f\"  {i+1}. {error.get('timing_description', 'N/A')}\")\n",
    "else:\n",
    "    print(\"\\n✓ All errors have been processed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Production Data Validation\n",
    "\n",
    "Now let's validate the system with real production data from the fixture file. This demonstrates that the self-healing parser works not just with controlled test inputs, but also with actual production failures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear error queue again for production data validation\n",
    "if error_queue_path.exists():\n",
    "    error_queue_path.unlink()\n",
    "    print(\"✓ Cleared error queue for production data validation\")\n",
    "else:\n",
    "    print(\"✓ Error queue already empty\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fixture data and populate error queue with real production failures\n",
    "from coding_agent.error_queue import append_error_to_queue\n",
    "\n",
    "# Use project_root from cell 1 for fixture path\n",
    "fixture_path = project_root / \"tests\" / \"fixtures\" / \"follow_up_tasks_202512121435.jsonl\"\n",
    "if not fixture_path.exists():\n",
    "    raise FileNotFoundError(f\"Fixture file not found: {fixture_path}\")\n",
    "df_production = pd.read_json(str(fixture_path), lines=True)\n",
    "\n",
    "# Filter for rows where deadline_at is null (parsing failures)\n",
    "failed_parses_production = df_production[df_production['deadline_at'].isna()]\n",
    "\n",
    "print(f\"Total rows in fixture: {len(df_production)}\")\n",
    "print(f\"Rows with parsing failures: {len(failed_parses_production)}\")\n",
    "\n",
    "# Add production errors to error queue\n",
    "errors_added = 0\n",
    "for _, row in failed_parses_production.iterrows():\n",
    "    error_entry = {\n",
    "        \"customer_id\": row.get('customer_id'),\n",
    "        \"deadline_at\": None,\n",
    "        \"timing_description\": row.get('timing_description'),\n",
    "        \"auxiliary_pretty\": row.get('auxiliary_pretty', '{}'),\n",
    "    }\n",
    "    \n",
    "    # Validate timing_description is a non-empty string\n",
    "    timing_desc = error_entry.get('timing_description', '')\n",
    "    if isinstance(timing_desc, str) and timing_desc.strip():\n",
    "        append_error_to_queue(str(error_queue_path), error_entry)\n",
    "        errors_added += 1\n",
    "\n",
    "print(f\"✓ Added {errors_added} production errors to error queue\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample production errors in queue\n",
    "production_errors = read_error_queue(error_queue_path)\n",
    "print(f\"Total production errors in queue: {len(production_errors)}\")\n",
    "print(\"\\nSample production errors:\")\n",
    "for i, error in enumerate(production_errors[:10]):\n",
    "    timing_desc = error.get('timing_description', 'N/A')\n",
    "    print(f\"  {i+1}. {timing_desc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have enough errors to run the agent\n",
    "production_error_count = get_error_count(error_queue_path)\n",
    "print(f\"Production errors in queue: {production_error_count}\")\n",
    "print(f\"Error threshold: {ERROR_THRESHOLD}\")\n",
    "\n",
    "if production_error_count >= ERROR_THRESHOLD:\n",
    "    print(\"✓ Enough production errors to activate agent\")\n",
    "    print(\"\\nNote: You can run the agent workflow again to process these production errors.\")\n",
    "    print(\"The workflow would cluster these real production patterns and generate\")\n",
    "    print(\"parser modules to handle them, just as it did with the controlled test inputs.\")\n",
    "else:\n",
    "    print(f\"⚠ Need at least {ERROR_THRESHOLD} errors to activate agent\")\n",
    "    print(f\"   (Current: {production_error_count})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Run Agent on Production Data**\n",
    "\n",
    "The cell below can be executed to process the production errors through the agent workflow. This demonstrates the full cycle with real production data. (You can skip this if you've already demonstrated the workflow above.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Run agent workflow on production errors\n",
    "# Uncomment the code below to process production errors through the agent\n",
    "\n",
    "# if production_error_count >= ERROR_THRESHOLD:\n",
    "#     # Generate new thread_id for this run\n",
    "#     production_thread_id = f\"coding_agent_production_{uuid.uuid4().hex[:8]}\"\n",
    "#     \n",
    "#     # Initialize workflow (reuse same configuration)\n",
    "#     production_workflow = CodingAgentWorkflow(\n",
    "#         node_llms=node_llms,\n",
    "#         node_prompts=node_prompts,\n",
    "#         thread_id=production_thread_id,\n",
    "#         error_queue_path=\"error_queue.jsonl\",\n",
    "#         parsers_dir=\"time_parser/parsers\",\n",
    "#         tests_dir=\"time_parser/tests\",\n",
    "#         rate_limiting_config=DEFAULT_RATE_LIMITING_CONFIG,\n",
    "#         fail_fast=False,\n",
    "#         error_logging=True,\n",
    "#         debug_logging=False,\n",
    "#         enforce_structured_llm_output=False,\n",
    "#     )\n",
    "#     \n",
    "#     # Create initial state\n",
    "#     production_initial_state = AnnotationState(\n",
    "#         messages=[],\n",
    "#         node_output=None,\n",
    "#         final_output=None,\n",
    "#     )\n",
    "#     \n",
    "#     # Run workflow\n",
    "#     print(\"Running agent workflow on production errors...\")\n",
    "#     production_result = production_workflow.run(initial_state=production_initial_state)\n",
    "#     \n",
    "#     print(\"\\n✓ Production workflow completed!\")\n",
    "#     print(f\"Success: {production_result.get('success', False)}\")\n",
    "#     print(f\"Processed clusters: {production_result.get('processed_clusters', [])}\")\n",
    "#     print(f\"Errors removed: {production_result.get('errors_removed_count', 0)}\")\n",
    "#     \n",
    "#     # Reload parser and test with production patterns\n",
    "#     parser = reload_parser(\"time_parser/parsers\")\n",
    "#     print(\"\\n✓ Parser reloaded with production-generated modules\")\n",
    "# else:\n",
    "#     print(\"Not enough errors to run agent workflow\")\n",
    "\n",
    "print(\"(Cell is commented out - uncomment to run agent on production data)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The self-healing time parser system has successfully:\n",
    "1. ✅ Collected parsing failures in the error queue\n",
    "2. ✅ Clustered errors by semantic similarity\n",
    "3. ✅ Generated parser modules for each error cluster\n",
    "4. ✅ Created comprehensive test files\n",
    "5. ✅ Validated all tests pass\n",
    "6. ✅ Updated the parser with new capabilities\n",
    "7. ✅ Removed processed errors from the queue\n",
    "\n",
    "The parser can now handle previously failing time expressions automatically!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
